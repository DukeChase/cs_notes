# 传统强化学习



# 大模型强化学习

## RLHF
**RLHF**（Reinforcement Learning from Human Feedback，人类反馈强化学习）

Imitation Learning


[ChatGPT 背后的“功臣”——RLHF 技术详解](https://huggingface.co/blog/zh/rlhf)

## PPO（Proximal Policy Optimization）

chat with gpt
https://chatgpt.com/c/6948ff06-b378-8331-9536-b271f40b5f2c


## DPO (Direct Preference Optimization)
**DPO**（Direct Preference Optimization，**直接偏好优化**）


## GRPO 
**Group Relative Policy Optimization**（分组相对策略优化）



Hugging Face RLHF Blog


TRL (Transformer Reinforcement Learning)

TRLX