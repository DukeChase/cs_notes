[qwen3-vl  技术报告](https://arxiv.org/pdf/2511.21631)

我们推出了 Qwen3-VL，这是迄今为止 Qwen 系列中功能最强大的视觉语言模型，在广泛的多模态基准测试中均取得了卓越的性能。它原生支持高达 256K 标记（tokens）的交错上下文，实现了文本、图像和视频的无缝集成。该模型系列包括稠密型（2B/4B/8B/32B）和混合专家型（30B-A3B/235B-A22B）变体，以适应不同的延迟与质量权衡。Qwen3-VL 具备三大核心支柱：（i）显著增强的纯文本理解能力，在多个案例中超越了同级别的纯文本骨干模型；（ii）强大的长上下文理解能力，为文本和交错多模态输入提供原生的 256K 标记窗口，从而在长文档和视频中实现忠实的保留、检索和交叉引用；（iii）在单图、多图和视频任务中展现出先进的多模态推理能力，在 MMMU 等综合评估以及 MathVista 和 MathVision 等视觉数学基准测试中表现领先。在架构方面，我们引入了三项关键升级：（i）增强型交错 MRoPE，用于加强图像和视频的跨时空建模；（ii）DeepStack 集成，有效利用多级 ViT 特征以收紧视觉与语言的对齐；（iii）视频的文本时间对齐，从 T-RoPE 演进为显式的文本时间戳对齐，以实现更精确的时间定位。在相近的标记预算和延迟限制下，Qwen3-VL 在稠密架构和混合专家（MoE）架构中均取得了优异性能。我们预景 Qwen3-VL 将成为现实工作流中基于图像的推理、智能体决策以及多模态代码智能的基础引擎。