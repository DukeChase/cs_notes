# è§†è§‰å¤§æ¨¡å‹çš„é¢„è®­ç»ƒèŒƒå¼æ¼”è¿›ï¼šä»æ¶æ„é©æ–°åˆ°è‡ªç›‘ç£å­¦ä¹ çš„æ·±åº¦æ¢ç´¢

## è§†è§‰Transformerçš„å¥ åŸºä¸é¢„è®­ç»ƒçš„åˆå§‹æ¢ç´¢

åœ¨æ·±åº¦å­¦ä¹ çš„å†å²é•¿æ²³ä¸­ï¼Œå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å‡­å€Ÿå…¶å†…åœ¨çš„å½’çº³åç½®ï¼ˆInductive Biasï¼‰ï¼Œå¦‚å±€éƒ¨æ€§ï¼ˆLocalityï¼‰å’Œç©ºé—´ä¸å˜æ€§ï¼ˆSpatial Invarianceï¼‰ï¼Œé•¿æœŸä»¥æ¥ä¸»å¯¼ç€è®¡ç®—æœºè§†è§‰é¢†åŸŸ[[0](https://www.v7labs.com/blog/vision-transformer-guide)]ã€‚CNNæ¶æ„é€šè¿‡å±‚å±‚å †å çš„å·ç§¯æ ¸å’Œæ± åŒ–å±‚ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°ä»å›¾åƒä¸­æå–ä»ä½çº§è¾¹ç¼˜ã€è§’ç‚¹åˆ°é«˜çº§è¯­ä¹‰ç‰¹å¾çš„å±‚æ¬¡åŒ–è¡¨ç¤ºï¼Œè¿™ä¸€ç‰¹æ€§ä¸äººç±»è§†è§‰ç³»ç»Ÿçš„æ„ŸçŸ¥æœºåˆ¶é«˜åº¦å»åˆï¼Œä½¿å…¶åœ¨å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹ã€è¯­ä¹‰åˆ†å‰²ç­‰ä¼—å¤šä»»åŠ¡ä¸­å–å¾—äº†è¾‰ç…Œæˆå°±ã€‚ç„¶è€Œï¼ŒCNNçš„è¿™ä¸€å¼ºå…ˆéªŒå‡è®¾ä¹Ÿæ„æˆäº†å…¶å‘å±•çš„â€œç»ç’ƒå¤©èŠ±æ¿â€ã€‚å°½ç®¡å…¶åœ¨å¤„ç†å±€éƒ¨ä¿¡æ¯æ—¶è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨å»ºæ¨¡å›¾åƒä¸­é•¿è·ç¦»ä¾èµ–å…³ç³»æ—¶ï¼ŒCNNåˆ™éœ€è¦é€šè¿‡æ·±å±‚ç»“æ„å’Œå·¨å¤§çš„æ„Ÿå—é‡æ¥é—´æ¥å®ç°ï¼Œè¿™ä¸ä»…å¢åŠ äº†æ¨¡å‹çš„å¤æ‚åº¦å’Œè®¡ç®—æˆæœ¬ï¼Œä¹Ÿå¯èƒ½å¯¼è‡´ä¿¡æ¯åœ¨ä¼ é€’è¿‡ç¨‹ä¸­çš„æŸå¤±æˆ–ç¨€é‡Šã€‚éšç€æ¨¡å‹è§„æ¨¡çš„ä¸æ–­æ‰©å¤§å’Œæ•°æ®é›†çš„æŒç»­å¢é•¿ï¼Œç ”ç©¶è€…ä»¬å¼€å§‹åæ€ï¼šæ˜¯å¦å­˜åœ¨ä¸€ç§æ›´å…·æ‰©å±•æ€§ã€èƒ½å¤Ÿæ›´ç›´æ¥åœ°æ•æ‰å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯çš„è§†è§‰æ¨¡å‹æ¶æ„ï¼Ÿè¿™ä¸€æ€è€ƒå‚¬ç”Ÿäº†è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNatural Language Processing, NLPï¼‰é¢†åŸŸä¸è®¡ç®—æœºè§†è§‰ï¼ˆComputer Vision, CVï¼‰é¢†åŸŸçš„ä¸€æ¬¡æ·±åˆ»äº¤æ±‡ã€‚2017å¹´ï¼ŒTransformeræ¶æ„å‡­å€Ÿå…¶æ ¸å¿ƒçš„è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ˆSelf-Attention Mechanismï¼‰åœ¨æœºå™¨ç¿»è¯‘ç­‰NLPä»»åŠ¡ä¸Šå–å¾—äº†çªç ´æ€§è¿›å±•ï¼Œå…¶èƒ½å¤ŸåŠ¨æ€åœ°è®¡ç®—åºåˆ—ä¸­ä»»æ„ä¸¤ä¸ªå…ƒç´ ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼Œä»è€Œå®Œç¾åœ°è§£å†³äº†é•¿è·ç¦»ä¾èµ–å»ºæ¨¡é—®é¢˜ã€‚è¿™ä¸€æˆåŠŸä¸ºè§†è§‰é¢†åŸŸçš„ç ”ç©¶è€…æä¾›äº†å…¨æ–°çš„çµæ„Ÿï¼šå¦‚æœå°†å›¾åƒè§†ä¸ºä¸€ä¸ªåºåˆ—ï¼ŒTransformeræ˜¯å¦ä¹Ÿèƒ½åœ¨è§†è§‰ä»»åŠ¡ä¸­å¤§æ”¾å¼‚å½©ï¼Ÿæ­£æ˜¯åœ¨è¿™ä¸€èƒŒæ™¯ä¸‹ï¼ŒVision Transformerï¼ˆViTï¼‰åº”è¿è€Œç”Ÿï¼Œå®ƒæ ‡å¿—ç€è§†è§‰æ¨¡å‹è®¾è®¡ç†å¿µçš„ä¸€æ¬¡æ ¹æœ¬æ€§å˜é©â€”â€”ä»ä¾èµ–äººå·¥è®¾è®¡çš„å½’çº³åç½®è½¬å‘äº†æ›´ä¸ºé€šç”¨çš„ã€æ•°æ®é©±åŠ¨çš„åºåˆ—å»ºæ¨¡èŒƒå¼[[0](https://www.v7labs.com/blog/vision-transformer-guide)]ã€‚

Vision Transformerçš„æ ¸å¿ƒæ€æƒ³åœ¨äºå°†æ ‡å‡†çš„Transformerç¼–ç å™¨ç›´æ¥åº”ç”¨äºå›¾åƒï¼Œå…¶å®ç°è¿‡ç¨‹åŒ…å«ä¸€ç³»åˆ—å…³é”®çš„é¢„å¤„ç†æ­¥éª¤ã€‚é¦–å…ˆï¼Œä¸€å¹…è¾“å…¥å›¾åƒè¢«åˆ†å‰²æˆä¸€ç³»åˆ—å›ºå®šå¤§å°çš„ã€ä¸é‡å çš„å›¾åƒå—ï¼ˆImage Patchesï¼‰ã€‚ä¾‹å¦‚ï¼Œå¯¹äºä¸€å¼ 224x224åƒç´ çš„å›¾åƒï¼Œè‹¥ä½¿ç”¨16x16çš„å›¾åƒå—å¤§å°ï¼Œåˆ™ä¼šå¾—åˆ°196ä¸ªå›¾åƒå—ã€‚æ¯ä¸ªå›¾åƒå—éšåè¢«å±•å¹³æˆä¸€ä¸ªä¸€ç»´å‘é‡ï¼Œå¹¶é€šè¿‡ä¸€ä¸ªå¯å­¦ä¹ çš„çº¿æ€§æŠ•å½±å±‚æ˜ å°„åˆ°ä¸€ä¸ªé«˜ç»´çš„åµŒå…¥ç©ºé—´ï¼ˆEmbedding Spaceï¼‰ï¼Œå½¢æˆæ‰€è°“çš„â€œPatch Embeddingsâ€ã€‚è¿™ä¸€è¿‡ç¨‹ç±»ä¼¼äºNLPä¸­å°†å•è¯è½¬æ¢ä¸ºè¯å‘é‡ï¼ˆWord Embeddingsï¼‰ï¼Œå®ƒå°†åŸå§‹çš„åƒç´ ä¿¡æ¯è½¬åŒ–ä¸ºæ¨¡å‹å¯ä»¥å¤„ç†çš„è¯­ä¹‰è¡¨ç¤ºã€‚ä¸ºäº†ä¿ç•™å›¾åƒå—åœ¨åŸå§‹å›¾åƒä¸­çš„ä½ç½®ä¿¡æ¯ï¼ŒViTè¿˜å¼•å…¥äº†ä¸€ç»„å¯å­¦ä¹ çš„ä½ç½®åµŒå…¥ï¼ˆPosition Embeddingsï¼‰ï¼Œå¹¶å°†å…¶åŠ åˆ°å¯¹åº”çš„Patch Embeddingsä¸Šã€‚è¿™ä½¿å¾—æ¨¡å‹èƒ½å¤ŸåŒºåˆ†ä¸åŒä½ç½®çš„å›¾åƒå—ï¼Œå¹¶ç†è§£å›¾åƒçš„ç©ºé—´ç»“æ„ã€‚æœ€åï¼Œä¸NLPä¸­çš„Transformerç±»ä¼¼ï¼Œä¸€ä¸ªç‰¹æ®Šçš„[class]æ ‡è®°ï¼ˆTokenï¼‰è¢«æ·»åŠ åˆ°è¿™ä¸ªå›¾åƒå—åºåˆ—çš„å¼€å¤´ã€‚è¿™ä¸ª[class]æ ‡è®°å¯¹åº”çš„æœ€ç»ˆè¾“å‡ºçŠ¶æ€ï¼Œè¢«è§†ä¸ºæ•´ä¸ªå›¾åƒçš„èšåˆè¡¨ç¤ºï¼Œå¹¶è¢«ç”¨äºå›¾åƒåˆ†ç±»ç­‰ä»»åŠ¡çš„æœ€ç»ˆé¢„æµ‹[[0](https://www.v7labs.com/blog/vision-transformer-guide)]ã€‚é€šè¿‡è¿™ä¸€ç³»åˆ—ç²¾å·§çš„è®¾è®¡ï¼ŒViTæˆåŠŸåœ°å°†äºŒç»´å›¾åƒé—®é¢˜è½¬åŒ–ä¸ºä¸€ç»´åºåˆ—é—®é¢˜ï¼Œä»è€Œèƒ½å¤Ÿç›´æ¥åˆ©ç”¨å¼ºå¤§çš„Transformeræ¶æ„è¿›è¡Œå»ºæ¨¡ã€‚ç„¶è€Œï¼Œè¿™ç§æ¶æ„çš„é€šç”¨æ€§ä¹Ÿå¸¦æ¥äº†æ–°çš„æŒ‘æˆ˜ã€‚ä¸CNNä¸åŒï¼ŒViTç¼ºä¹å¯¹å›¾åƒçš„å†…åœ¨å…ˆéªŒçŸ¥è¯†ï¼Œå®ƒéœ€è¦ä»å¤´å¼€å§‹å­¦ä¹ å›¾åƒçš„ç©ºé—´ç»“æ„å’Œå±€éƒ¨ç‰¹å¾ã€‚è¿™æ„å‘³ç€ViTå¯¹æ•°æ®çš„è§„æ¨¡å’Œè´¨é‡æœ‰ç€æé«˜çš„ä¾èµ–æ€§ã€‚åœ¨æ•°æ®é‡æœ‰é™çš„æƒ…å†µä¸‹ï¼ŒViTçš„è¡¨ç°å¾€å¾€ä¸å¦‚åŒç­‰è§„æ¨¡çš„CNNï¼Œå› ä¸ºCNNçš„å½’çº³åç½®ä¸ºå…¶æä¾›äº†è‰¯å¥½çš„åˆå§‹åŒ–å’Œæ­£åˆ™åŒ–ã€‚åªæœ‰å½“é¢„è®­ç»ƒæ•°æ®é›†çš„è§„æ¨¡è¾¾åˆ°æ•°åƒä¸‡ç”šè‡³ä¸Šäº¿å¼ å›¾åƒæ—¶ï¼ŒViTæ‰èƒ½å……åˆ†å±•ç°å…¶å¼ºå¤§çš„å­¦ä¹ èƒ½åŠ›ï¼Œå¹¶åœ¨å„ç§å›¾åƒåˆ†ç±»åŸºå‡†æµ‹è¯•ä¸Šç¨³å®šåœ°è¶…è¶ŠCNNæ¨¡å‹[[5](https://www.articsledge.com/post/vision-transformer-vit)]ã€‚è¿™ä¸€å‘ç°æ·±åˆ»æ­ç¤ºäº†ViTçš„â€œè§„æ¨¡æ³•åˆ™â€ï¼ˆScaling Lawï¼‰ï¼šæ¨¡å‹çš„æ€§èƒ½ä¸å…¶è§„æ¨¡ï¼ˆåŒ…æ‹¬å‚æ•°é‡ã€è®¡ç®—é‡å’Œæ•°æ®é‡ï¼‰ä¹‹é—´å­˜åœ¨å¼ºç›¸å…³æ€§ã€‚ViTçš„å‡ºç°ï¼Œä¸ä»…ä¸ºè§†è§‰é¢†åŸŸæä¾›äº†ä¸€ç§å…¨æ–°çš„ã€æå…·æ‰©å±•æ€§çš„éª¨å¹²ç½‘ç»œï¼ˆBackboneï¼‰ï¼Œæ›´é‡è¦çš„æ˜¯ï¼Œå®ƒå¼€å¯äº†ä¸€ä¸ªå…³äºå¦‚ä½•æœ‰æ•ˆé¢„è®­ç»ƒè¿™äº›å¤§è§„æ¨¡æ¨¡å‹çš„æ—¶ä»£ã€‚å®ƒå°†ç ”ç©¶çš„ç„¦ç‚¹ä»â€œè®¾è®¡æ›´å¥½çš„ç½‘ç»œæ¶æ„â€éƒ¨åˆ†è½¬ç§»åˆ°äº†â€œå¦‚ä½•åˆ©ç”¨æµ·é‡æ•°æ®è¿›è¡Œé«˜æ•ˆé¢„è®­ç»ƒâ€ï¼Œä¸ºåç»­ä¸€ç³»åˆ—è‡ªç›‘ç£å­¦ä¹ å’Œå¤šæ¨¡æ€å­¦ä¹ æ–¹æ³•çš„çˆ†å‘å¥ å®šäº†åšå®çš„åŸºç¡€ã€‚

ViTçš„æå‡ºï¼Œè™½ç„¶åœ¨æ¶æ„ä¸Šå®ç°äº†ä»CNNåˆ°Transformerçš„è·¨è¶Šï¼Œä½†å…¶é¢„è®­ç»ƒæ–¹å¼åœ¨åˆæœŸä»ç„¶éµå¾ªç€ä¼ ç»Ÿçš„ç›‘ç£å­¦ä¹ èŒƒå¼ï¼Œå³åœ¨å¸¦æœ‰å¤§è§„æ¨¡äººå·¥æ ‡æ³¨çš„æ•°æ®é›†ï¼ˆå¦‚ImageNet-21Kã€JFT-300Mç­‰ï¼‰ä¸Šè¿›è¡Œå›¾åƒåˆ†ç±»ä»»åŠ¡çš„é¢„è®­ç»ƒ[[7](https://viso.ai/deep-learning/vision-transformer-vit)]ã€‚è¿™ç§ç›‘ç£é¢„è®­ç»ƒï¼ˆSupervised Pre-trainingï¼‰çš„ç›®æ ‡æ˜¯è®©æ¨¡å‹å­¦ä¹ åˆ°èƒ½å¤Ÿæ­£ç¡®åŒºåˆ†æ•°åƒä¸ªç”šè‡³æ•°ä¸‡ä¸ªç±»åˆ«çš„è§†è§‰ç‰¹å¾ã€‚é€šè¿‡æœ€å°åŒ–é¢„æµ‹ç±»åˆ«ä¸çœŸå®ç±»åˆ«ä¹‹é—´çš„äº¤å‰ç†µæŸå¤±ï¼ˆCross-Entropy Lossï¼‰ï¼Œæ¨¡å‹è¢«è¿«å­¦ä¹ åˆ°å¯¹ä¸‹æ¸¸ä»»åŠ¡ï¼ˆå¦‚å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹ï¼‰æœ‰ç”¨çš„é€šç”¨è¡¨ç¤ºã€‚é¢„è®­ç»ƒå®Œæˆåï¼Œæ¨¡å‹é€šå¸¸ä¼šåœ¨ç‰¹å®šçš„ä¸‹æ¸¸ä»»åŠ¡æ•°æ®é›†ä¸Šè¿›è¡Œå¾®è°ƒï¼ˆFine-tuningï¼‰ï¼Œå³ä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡åœ¨ä¸‹æ¸¸ä»»åŠ¡çš„æ•°æ®ä¸Šç»§ç»­è®­ç»ƒæ¨¡å‹çš„éƒ¨åˆ†æˆ–å…¨éƒ¨å‚æ•°ï¼Œä»¥ä½¿å…¶é€‚åº”æ–°çš„ä»»åŠ¡åˆ†å¸ƒã€‚è¿™ç§â€œé¢„è®­ç»ƒ-å¾®è°ƒâ€ï¼ˆPre-train and Fine-tuneï¼‰çš„èŒƒå¼å·²ç»æˆä¸ºæ·±åº¦å­¦ä¹ é¢†åŸŸï¼Œç‰¹åˆ«æ˜¯è§†è§‰é¢†åŸŸçš„æ ‡å‡†æµç¨‹ã€‚ç„¶è€Œï¼Œç›‘ç£é¢„è®­ç»ƒçš„å±€é™æ€§ä¹Ÿæ—¥ç›Šå‡¸æ˜¾ã€‚æœ€æ ¸å¿ƒçš„é—®é¢˜åœ¨äºå…¶å¯¹æµ·é‡é«˜è´¨é‡æ ‡æ³¨æ•°æ®çš„æåº¦ä¾èµ–ã€‚äººå·¥æ ‡æ³¨æ•°æ®ä¸ä»…æˆæœ¬é«˜æ˜‚ã€è€—æ—¶è€—åŠ›ï¼Œè€Œä¸”å…¶è¦†ç›–çš„è¯­ä¹‰èŒƒå›´å’Œé¢†åŸŸå¤šæ ·æ€§ä¹Ÿå—åˆ°é™åˆ¶ã€‚ä¾‹å¦‚ï¼ŒImageNetè™½ç„¶åŒ…å«è¶…è¿‡1400ä¸‡å¼ å›¾åƒå’Œ2ä¸‡å¤šä¸ªç±»åˆ«ï¼Œä½†å…¶ç±»åˆ«ä½“ç³»ä»ç„¶ç›¸å¯¹å›ºå®šï¼Œæ— æ³•è¦†ç›–ç°å®ä¸–ç•Œä¸­æ— ç©·æ— å°½çš„è§†è§‰æ¦‚å¿µã€‚è¿™ç§å±€é™æ€§ä½¿å¾—é€šè¿‡ç›‘ç£é¢„è®­ç»ƒå­¦åˆ°çš„è§†è§‰è¡¨ç¤ºå¯èƒ½å­˜åœ¨åè§ï¼Œå¹¶ä¸”éš¾ä»¥æ³›åŒ–åˆ°é‚£äº›åœ¨é¢„è®­ç»ƒæ•°æ®é›†ä¸­ç½•è§æˆ–å®Œå…¨ä¸å­˜åœ¨çš„è§†è§‰é¢†åŸŸæˆ–æ¦‚å¿µã€‚æ­¤å¤–ï¼Œç›‘ç£å­¦ä¹ ä»»åŠ¡ï¼ˆå¦‚å›¾åƒåˆ†ç±»ï¼‰æœ¬èº«å¯èƒ½å¹¶éå­¦ä¹ ä¸°å¯Œè§†è§‰è¡¨ç¤ºçš„æœ€ä¼˜é€”å¾„ã€‚æ¨¡å‹å¯èƒ½åªå­¦ä¹ åˆ°åŒºåˆ†ä¸åŒç±»åˆ«æ‰€éœ€çš„æœ€å°åŒ–ç‰¹å¾ï¼Œè€Œå¿½ç•¥äº†å›¾åƒä¸­å…¶ä»–ä¸°å¯Œçš„é«˜å±‚è¯­ä¹‰ä¿¡æ¯å’Œçº¹ç†ã€å½¢çŠ¶ç­‰ç»†èŠ‚ã€‚è¿™ç§â€œçŸ¥å…¶ç„¶ï¼Œè€Œä¸çŸ¥å…¶æ‰€ä»¥ç„¶â€çš„å­¦ä¹ æ–¹å¼ï¼Œé™åˆ¶äº†æ¨¡å‹è¡¨ç¤ºèƒ½åŠ›çš„ä¸Šé™ã€‚å› æ­¤ï¼Œç ”ç©¶è€…ä»¬å¼€å§‹ç§¯ææ¢ç´¢æ‘†è„±å¯¹äººå·¥æ ‡æ³¨ä¾èµ–çš„é¢„è®­ç»ƒæ–¹æ³•ï¼Œå³è‡ªç›‘ç£å­¦ä¹ ï¼ˆSelf-Supervised Learning, SSLï¼‰ã€‚è‡ªç›‘ç£å­¦ä¹ çš„æ ¸å¿ƒæ€æƒ³æ˜¯ä»æ•°æ®è‡ªèº«ä¸­æ„é€ ç›‘ç£ä¿¡å·ï¼Œé€šè¿‡è®¾è®¡å„ç§â€œä»£ç†ä»»åŠ¡â€ï¼ˆProxy Tasksï¼‰æ¥è®©æ¨¡å‹å­¦ä¹ æœ‰ç”¨çš„è¡¨ç¤ºã€‚åœ¨ViTçš„èƒŒæ™¯ä¸‹ï¼Œè¿™æ„å‘³ç€åˆ©ç”¨å›¾åƒæœ¬èº«çš„ç»“æ„å’Œä¿¡æ¯ï¼Œè€Œä¸ä¾èµ–ä»»ä½•äººå·¥æ ‡ç­¾ï¼Œæ¥è®­ç»ƒæ¨¡å‹ã€‚è¿™ä¸€æ¢ç´¢å‚¬ç”Ÿäº†è§†è§‰é¢„è®­ç»ƒé¢†åŸŸçš„ä¸¤å¤§ä¸»æµæŠ€æœ¯è·¯çº¿ï¼šä¸€æ˜¯ä»¥æ©ç å»ºæ¨¡ï¼ˆMasked Modelingï¼‰ä¸ºä»£è¡¨çš„æ–¹æ³•ï¼Œå…¶çµæ„Ÿæ¥æºäºNLPé¢†åŸŸçš„BERTï¼›äºŒæ˜¯ä»¥å¯¹æ¯”å­¦ä¹ ï¼ˆContrastive Learningï¼‰ä¸ºä»£è¡¨çš„æ–¹æ³•ï¼Œå…¶ç›®æ ‡æ˜¯æ‹‰è¿‘ç›¸ä¼¼æ ·æœ¬çš„è¡¨ç¤ºï¼Œæ¨è¿œä¸ç›¸ä¼¼æ ·æœ¬çš„è¡¨ç¤ºã€‚ViTçš„é€šç”¨æ¶æ„ä¸ºè¿™ä¸¤å¤§è·¯çº¿çš„è“¬å‹ƒå‘å±•æä¾›äº†ç†æƒ³çš„è¯•éªŒåœºï¼Œå› ä¸ºå®ƒä¸åƒCNNé‚£æ ·å…·æœ‰å¼ºçƒˆçš„å½’çº³åç½®ï¼Œèƒ½å¤Ÿæ›´çµæ´»åœ°é€‚åº”å„ç§è‡ªç›‘ç£é¢„è®­ç»ƒç›®æ ‡ï¼Œä»è€Œä»æµ·é‡æ— æ ‡æ³¨æ•°æ®ä¸­æŒ–æ˜å‡ºæ›´æ·±å±‚æ¬¡çš„è§†è§‰çŸ¥è¯†ã€‚

## CLIPï¼šå¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ çš„èŒƒå¼é©å‘½

åœ¨Vision Transformerä¸ºè§†è§‰æ¨¡å‹æ¶æ„å¸¦æ¥é©æ–°ï¼Œå¹¶å¼•å‘å¯¹è‡ªç›‘ç£é¢„è®­ç»ƒæ·±åº¦æ€è€ƒçš„åŒæ—¶ï¼Œå¦ä¸€æ¡å½±å“æ·±è¿œçš„æ¢ç´¢è·¯å¾„æ­£åœ¨æ‚„ç„¶å…´èµ·ï¼Œå®ƒè¯•å›¾æ‰“ç ´è§†è§‰å’Œè¯­è¨€ä¸¤å¤§æ¨¡æ€ä¹‹é—´çš„å£å’ï¼Œä»æ›´å¹¿é˜”çš„è·¨æ¨¡æ€æ•°æ®ä¸­å­¦ä¹ ã€‚è¿™æ¡è·¯å¾„çš„é›†å¤§æˆè€…ï¼Œä¾¿æ˜¯ç”±OpenAIæå‡ºçš„CLIPï¼ˆContrastive Languageâ€“Image Pre-trainingï¼‰æ¨¡å‹[[30](https://openai.com/index/clip)]ã€‚CLIPçš„å‡ºç°ï¼Œä¸ä»…åœ¨æŠ€æœ¯ä¸Šå®ç°äº†é‡å¤§çªç ´ï¼Œæ›´åœ¨ç†å¿µä¸Šå¯¹è§†è§‰é¢„è®­ç»ƒçš„èŒƒå¼è¿›è¡Œäº†ä¸€æ¬¡æ·±åˆ»çš„é©å‘½ã€‚å®ƒä¸å†å°†è§†è§‰è§†ä¸ºä¸€ä¸ªå­¤ç«‹çš„é¢†åŸŸï¼Œè€Œæ˜¯å°†å…¶ä¸è‡ªç„¶è¯­è¨€è¿™ä¸€æ‰¿è½½ç€ä¸°å¯Œè¯­ä¹‰çŸ¥è¯†çš„åª’ä»‹ç´§å¯†ç»“åˆï¼Œé€šè¿‡å­¦ä¹ å›¾åƒå’Œæ–‡æœ¬ä¹‹é—´çš„å¯¹åº”å…³ç³»ï¼Œæ¥è·å¾—å‰æ‰€æœªæœ‰çš„å¼ºå¤§è§†è§‰ç†è§£èƒ½åŠ›å’Œæ³›åŒ–æ€§ã€‚CLIPçš„æ ¸å¿ƒæ€æƒ³å¼‚å¸¸ç®€æ´è€Œä¼˜é›…ï¼šç»™å®šä¸€ä¸ªåŒ…å«ï¼ˆå›¾åƒï¼Œæ–‡æœ¬ï¼‰å¯¹çš„åºå¤§æ•°æ®é›†ï¼Œæ¨¡å‹éœ€è¦å­¦ä¹ åˆ¤æ–­å“ªäº›æ–‡æœ¬æè¿°ä¸å“ªäº›å›¾åƒæ˜¯åŒ¹é…çš„[[33](https://arxiv.org/abs/2103.00020)]ã€‚è¿™ä¸ªä»»åŠ¡è¢«ç§°ä¸ºå¯¹æ¯”å­¦ä¹ ï¼Œå…¶ç›®æ ‡ä¸æ˜¯å»è¯†åˆ«å›¾åƒä¸­çš„å…·ä½“ç‰©ä½“ï¼ˆå¦‚â€œçŒ«â€æˆ–â€œç‹—â€ï¼‰ï¼Œè€Œæ˜¯å»å­¦ä¹ ä¸€ä¸ªåµŒå…¥ç©ºé—´ï¼Œåœ¨è¿™ä¸ªç©ºé—´ä¸­ï¼ŒåŒ¹é…çš„å›¾åƒå’Œæ–‡æœ¬å¯¹çš„è¡¨ç¤ºå‘é‡åœ¨å‡ ä½•ä¸Šç›¸äº’é è¿‘ï¼Œè€Œä¸åŒ¹é…çš„å›¾åƒå’Œæ–‡æœ¬å¯¹çš„è¡¨ç¤ºå‘é‡åˆ™ç›¸äº’è¿œç¦»ã€‚è¿™ç§å­¦ä¹ æ–¹å¼å·§å¦™åœ°åˆ©ç”¨äº†äº’è”ç½‘ä¸Šå‡ ä¹æ— ç©·æ— å°½çš„ã€è‡ªç„¶å­˜åœ¨çš„å›¾åƒ-æ–‡æœ¬é…å¯¹æ•°æ®ï¼Œä¾‹å¦‚ç½‘é¡µä¸­çš„å›¾ç‰‡åŠå…¶æ ‡é¢˜ã€ç¤¾äº¤åª’ä½“ä¸Šçš„å›¾ç‰‡åŠå…¶æè¿°ç­‰ã€‚è¿™äº›æ•°æ®çš„æµ·é‡æ€§å’Œå¤šæ ·æ€§ï¼Œè¿œè¶…ä»»ä½•äººå·¥æ„å»ºçš„æ ‡æ³¨æ•°æ®é›†ï¼Œä¸ºCLIPæä¾›äº†å‰æ‰€æœªæœ‰çš„â€œå…»æ–™â€ã€‚

CLIPçš„æ¶æ„è®¾è®¡ä¹Ÿå……åˆ†ä½“ç°äº†å…¶å¤šæ¨¡æ€çš„ç‰¹æ€§ã€‚å®ƒåŒ…å«ä¸¤ä¸ªç‹¬ç«‹çš„ç¼–ç å™¨ï¼šä¸€ä¸ªå›¾åƒç¼–ç å™¨ï¼ˆImage Encoderï¼‰å’Œä¸€ä¸ªæ–‡æœ¬ç¼–ç å™¨ï¼ˆText Encoderï¼‰[[31](https://en.wikipedia.org/wiki/Contrastive_Language-Image_Pre-training)]ã€‚å›¾åƒç¼–ç å™¨å¯ä»¥é‡‡ç”¨å¦‚ViTæˆ–ResNetç­‰ä¸»æµçš„è§†è§‰éª¨å¹²ç½‘ç»œï¼Œè´Ÿè´£å°†è¾“å…¥çš„å›¾åƒæ˜ å°„ä¸ºä¸€ä¸ªé«˜ç»´çš„ç‰¹å¾å‘é‡ã€‚æ–‡æœ¬ç¼–ç å™¨åˆ™é€šå¸¸é‡‡ç”¨Transformeræ¶æ„ï¼Œè´Ÿè´£å°†è¾“å…¥çš„æ–‡æœ¬æè¿°ä¹Ÿæ˜ å°„ä¸ºä¸€ä¸ªç›¸åŒç»´åº¦çš„é«˜ç»´ç‰¹å¾å‘é‡ã€‚åœ¨é¢„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒCLIPä½¿ç”¨ä¸€ä¸ªåä¸ºInfoNCEçš„å¯¹æ¯”æŸå¤±å‡½æ•°ã€‚å…·ä½“æ¥è¯´ï¼Œå¯¹äºä¸€ä¸ªæ‰¹æ¬¡ï¼ˆBatchï¼‰ä¸­çš„Nä¸ªï¼ˆå›¾åƒï¼Œæ–‡æœ¬ï¼‰å¯¹ï¼ŒCLIPä¼šè®¡ç®—æ‰€æœ‰å›¾åƒç‰¹å¾å’Œæ‰€æœ‰æ–‡æœ¬ç‰¹å¾ä¹‹é—´çš„N x Nä¸ªä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆCosine Similarityï¼‰ã€‚å¯¹äºä»»ä½•ä¸€ä¸ªæ­£ç¡®çš„ï¼ˆå›¾åƒiï¼Œæ–‡æœ¬iï¼‰å¯¹ï¼Œå…¶ç›®æ ‡æ˜¯æœ€å¤§åŒ–å®ƒä»¬ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼ŒåŒæ—¶æœ€å°åŒ–å›¾åƒiä¸æ‰¹æ¬¡ä¸­æ‰€æœ‰å…¶ä»–ä¸åŒ¹é…æ–‡æœ¬ï¼ˆæ–‡æœ¬jï¼Œjâ‰ iï¼‰çš„ç›¸ä¼¼åº¦ï¼Œä»¥åŠæ–‡æœ¬iä¸æ‰¹æ¬¡ä¸­æ‰€æœ‰å…¶ä»–ä¸åŒ¹é…å›¾åƒï¼ˆå›¾åƒjï¼Œjâ‰ iï¼‰çš„ç›¸ä¼¼åº¦ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡å‹è¢«è¿«å­¦ä¹ åˆ°å›¾åƒå†…å®¹å’Œæ–‡æœ¬è¯­ä¹‰ä¹‹é—´æ·±åˆ»çš„å¯¹é½å…³ç³»ã€‚å›¾åƒç¼–ç å™¨ä¸ä»…è¦ç†è§£å›¾åƒä¸­åŒ…å«äº†ä»€ä¹ˆï¼Œè¿˜è¦ä»¥ä¸€ç§ä¸æ–‡æœ¬ç¼–ç å™¨ç†è§£è¯­è¨€çš„æ–¹å¼ç›¸å…¼å®¹çš„æ–¹å¼è¿›è¡Œç†è§£ã€‚ä¾‹å¦‚ï¼Œæ¨¡å‹ä¸ä»…éœ€è¦å­¦ä¼šè¯†åˆ«å‡ºâ€œä¸€åªæŸ¯åŸºçŠ¬åœ¨è‰åœ°ä¸Šè¿½çƒâ€çš„å›¾åƒï¼Œè¿˜è¦å°†è¿™å¹…å›¾åƒçš„è¡¨ç¤ºä¸â€œä¸€åªæŸ¯åŸºçŠ¬åœ¨è‰åœ°ä¸Šè¿½çƒâ€è¿™å¥è¯çš„è¡¨ç¤ºç´§å¯†è”ç³»èµ·æ¥ã€‚

CLIPè¿™ç§é¢„è®­ç»ƒèŒƒå¼å¸¦æ¥çš„æœ€å¼•äººæ³¨ç›®çš„æˆæœæ˜¯å…¶å“è¶Šçš„é›¶æ ·æœ¬è¿ç§»å­¦ä¹ ï¼ˆZero-shot Transferï¼‰èƒ½åŠ›[[32](https://github.com/openai/CLIP)]ã€‚åœ¨ä¼ ç»Ÿçš„â€œé¢„è®­ç»ƒ-å¾®è°ƒâ€èŒƒå¼ä¸­ï¼Œé¢„è®­ç»ƒæ¨¡å‹éœ€è¦åœ¨ä¸‹æ¸¸ä»»åŠ¡çš„æœ‰æ ‡ç­¾æ•°æ®ä¸Šè¿›è¡Œå¾®è°ƒæ‰èƒ½é€‚åº”æ–°ä»»åŠ¡ã€‚è€ŒCLIPåˆ™å®Œå…¨è·³è¿‡äº†å¾®è°ƒæ­¥éª¤ã€‚åœ¨é¢„è®­ç»ƒå®Œæˆåï¼ŒCLIPå¯ä»¥ç›´æ¥åº”ç”¨äºå„ç§å›¾åƒåˆ†ç±»ä»»åŠ¡ï¼Œè€Œæ— éœ€ä»»ä½•ä»»åŠ¡ç‰¹å®šçš„è®­ç»ƒã€‚å…¶å®ç°æ–¹å¼éå¸¸å·§å¦™ï¼šå¯¹äºä¸€ä¸ªç»™å®šçš„å›¾åƒåˆ†ç±»ä»»åŠ¡ï¼ŒCLIPä¼šä¸ºæ¯ä¸ªç±»åˆ«æ„é€ ä¸€ä¸ªæ–‡æœ¬æç¤ºï¼ˆPromptï¼‰ï¼Œä¾‹å¦‚â€œA photo of a {class}â€ã€‚ç„¶åï¼Œå®ƒä½¿ç”¨é¢„è®­ç»ƒå¥½çš„æ–‡æœ¬ç¼–ç å™¨ä¸ºæ‰€æœ‰è¿™äº›ç±»åˆ«çš„æ–‡æœ¬æç¤ºè®¡ç®—ç‰¹å¾å‘é‡ã€‚åŒæ—¶ï¼Œå®ƒä½¿ç”¨å›¾åƒç¼–ç å™¨ä¸ºå¾…åˆ†ç±»çš„å›¾åƒè®¡ç®—ç‰¹å¾å‘é‡ã€‚æœ€åï¼Œé€šè¿‡è®¡ç®—å›¾åƒç‰¹å¾å‘é‡ä¸æ‰€æœ‰ç±»åˆ«æ–‡æœ¬ç‰¹å¾å‘é‡çš„ç›¸ä¼¼åº¦ï¼Œå¹¶å°†ç›¸ä¼¼åº¦æœ€é«˜çš„æ–‡æœ¬æç¤ºæ‰€å¯¹åº”çš„ç±»åˆ«ä½œä¸ºå›¾åƒçš„é¢„æµ‹ç»“æœã€‚è¿™ç§â€œå°†å›¾åƒåˆ†ç±»ä»»åŠ¡è½¬åŒ–ä¸ºå›¾åƒ-æ–‡æœ¬åŒ¹é…ä»»åŠ¡â€çš„æ–¹å¼ï¼Œä½¿å¾—CLIPå±•ç°å‡ºäº†æƒŠäººçš„çµæ´»æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚å®ƒåœ¨åŒ…æ‹¬ImageNetåœ¨å†…çš„æ•°åä¸ªå›¾åƒåˆ†ç±»åŸºå‡†æµ‹è¯•ä¸Šï¼Œä»…é€šè¿‡é›¶æ ·æœ¬å­¦ä¹ å°±å–å¾—äº†å¯ä¸å½“æ—¶æœ€å…ˆè¿›çš„ã€ç»è¿‡å®Œå…¨ç›‘ç£é¢„è®­ç»ƒå’Œå¾®è°ƒçš„æ¨¡å‹ç›¸åª²ç¾çš„æ€§èƒ½[[30](https://openai.com/index/clip)]ã€‚è¿™è¯æ˜äº†CLIPé€šè¿‡å¤§è§„æ¨¡å¯¹æ¯”å­¦ä¹ å­¦åˆ°çš„è§†è§‰è¡¨ç¤ºå…·æœ‰æå¼ºçš„é€šç”¨æ€§å’Œé²æ£’æ€§ã€‚

CLIPçš„æˆåŠŸæ ‡å¿—ç€è§†è§‰é¢„è®­ç»ƒè¿›å…¥äº†ä¸€ä¸ªå…¨æ–°çš„é˜¶æ®µã€‚å®ƒè¯æ˜äº†ï¼Œé€šè¿‡åˆ©ç”¨æµ·é‡ã€å˜ˆæ‚ä½†å¤šæ ·åŒ–çš„è‡ªç„¶è¯­è¨€ç›‘ç£ï¼Œå¯ä»¥å­¦ä¹ åˆ°è¿œè¶…ä¼ ç»Ÿç›‘ç£å­¦ä¹ çš„è§†è§‰æ¦‚å¿µã€‚å…¶æ„ä¹‰æ˜¯å¤šæ–¹é¢çš„ï¼šé¦–å…ˆï¼Œå®ƒæå¤§åœ°æ‰©å±•äº†è§†è§‰æ¨¡å‹çš„â€œè¯æ±‡é‡â€ã€‚ä¼ ç»Ÿæ¨¡å‹çš„è¯†åˆ«èƒ½åŠ›å—é™äºé¢„è®­ç»ƒæ•°æ®é›†çš„ç±»åˆ«æ•°é‡ï¼Œè€ŒCLIPçš„è¯†åˆ«èƒ½åŠ›ç†è®ºä¸Šå—é™äºå…¶æ–‡æœ¬ç¼–ç å™¨çš„è¯æ±‡é‡ï¼Œå¯ä»¥è¦†ç›–æˆåƒä¸Šä¸‡ç”šè‡³æ›´å¤šçš„æ¦‚å¿µã€‚å…¶æ¬¡ï¼Œå®ƒä¸ºè§†è§‰æ¨¡å‹å¸¦æ¥äº†å‰æ‰€æœªæœ‰çš„å¼€æ”¾æ€§ï¼ˆOpen Vocabularyï¼‰å’Œå¯ç»„åˆæ€§ï¼ˆCompositionalityï¼‰ã€‚ç”±äºCLIPç†è§£è¯­è¨€ï¼Œå®ƒå¯ä»¥å¤„ç†é‚£äº›åœ¨é¢„è®­ç»ƒä¸­ä»æœªè§è¿‡çš„ã€ç”±å¤šä¸ªè¯ç»„åˆè€Œæˆçš„æ–°æ¦‚å¿µï¼Œä¾‹å¦‚â€œä¸€ä¸ªæˆ´ç€å¸½å­çš„ã€éª‘åœ¨è‡ªè¡Œè½¦ä¸Šçš„å¤§è±¡â€ã€‚æœ€åï¼ŒCLIPçš„æˆåŠŸä¹Ÿä¸ºåç»­çš„è§†è§‰-è¯­è¨€å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆå¦‚DALL-Eç³»åˆ—ã€Stable Diffusionç­‰ï¼‰çš„è¯ç”Ÿé“ºå¹³äº†é“è·¯ï¼Œå®ƒæä¾›äº†ä¸€ç§å¼ºå¤§çš„ã€å°†è§†è§‰å’Œè¯­ä¹‰å¯¹é½çš„è¡¨ç¤ºç©ºé—´ï¼Œæˆä¸ºè¿æ¥è¿™ä¸¤ä¸ªæ¨¡æ€çš„å…³é”®æ¡¥æ¢ã€‚ç„¶è€Œï¼ŒCLIPä¹Ÿå¹¶éå®Œç¾æ— ç‘•ã€‚å…¶å¯¹æ¯”å­¦ä¹ èŒƒå¼åœ¨å¤„ç†ä¸€äº›éœ€è¦ç²¾ç»†è§†è§‰è¾¨åˆ«æˆ–ç»“æ„åŒ–ç†è§£çš„ä»»åŠ¡æ—¶ï¼Œå¯èƒ½ä¸å¦‚ä¸“é—¨è®¾è®¡çš„æ©ç å»ºæ¨¡æ–¹æ³•ã€‚æ­¤å¤–ï¼ŒCLIPçš„æ€§èƒ½ä¹Ÿé«˜åº¦ä¾èµ–äºé¢„è®­ç»ƒæ•°æ®çš„è§„æ¨¡å’Œè´¨é‡ï¼Œä»¥åŠæ–‡æœ¬æç¤ºçš„è®¾è®¡ã€‚å°½ç®¡å¦‚æ­¤ï¼ŒCLIPä½œä¸ºå¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ çš„é‡Œç¨‹ç¢‘ï¼Œå…¶æ ¸å¿ƒæ€æƒ³â€”â€”ä»è·¨æ¨¡æ€çš„å…³è”ä¸­å­¦ä¹ â€”â€”å·²ç»æ·±åˆ»åœ°æ”¹å˜äº†æˆ‘ä»¬å¯¹å¦‚ä½•æ„å»ºå¼ºå¤§è§†è§‰ç³»ç»Ÿçš„è®¤çŸ¥ï¼Œå¹¶æˆä¸ºäº†åç»­ä¼—å¤šè§†è§‰åŸºç¡€æ¨¡å‹å‘å±•çš„é‡è¦åŸºçŸ³ã€‚

## DINOä¸iBOTï¼šè‡ªç›‘ç£æ©ç å»ºæ¨¡çš„æ·±åº¦æ¼”åŒ–

åœ¨CLIPé€šè¿‡å¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ å¼€è¾Ÿæ–°å¤©åœ°çš„åŒæ—¶ï¼Œå¦ä¸€è‚¡å¼ºå¤§çš„åŠ›é‡åœ¨çº¯è§†è§‰çš„è‡ªç›‘ç£å­¦ä¹ é¢†åŸŸå†…æ¶ŒåŠ¨å¹¶èµ°å‘æˆç†Ÿã€‚è¿™è‚¡åŠ›é‡èšç„¦äºä¸€ä¸ªæ ¸å¿ƒæ€æƒ³ï¼šæ©ç å»ºæ¨¡ï¼ˆMasked Modelingï¼‰ï¼Œå³åƒNLPé¢†åŸŸçš„BERTä¸€æ ·ï¼Œé€šè¿‡é®ç›–è¾“å…¥çš„ä¸€éƒ¨åˆ†å¹¶è¿«ä½¿æ¨¡å‹å»é¢„æµ‹è¢«é®ç›–çš„å†…å®¹ï¼Œä»è€Œå­¦ä¹ åˆ°æ·±å±‚çš„ã€ç»“æ„åŒ–çš„æ•°æ®è¡¨ç¤ºã€‚è¿™ä¸€è·¯çº¿åœ¨è§†è§‰é¢†åŸŸçš„æ¢ç´¢ä¸­ï¼Œè¯ç”Ÿäº†ä¸¤ä¸ªé‡Œç¨‹ç¢‘å¼çš„æ¨¡å‹ï¼šDINOï¼ˆSelf-Distillation with NO labelsï¼‰å’ŒiBOTï¼ˆImage BERT Pre-Training with Online Tokenizerï¼‰ã€‚å®ƒä»¬å…±åŒä»£è¡¨äº†è‡ªç›‘ç£è§†è§‰é¢„è®­ç»ƒä»åˆæ­¥å°è¯•åˆ°é«˜åº¦ç²¾å¯†åŒ–çš„æ¼”è¿›è¿‡ç¨‹ï¼Œå±•ç¤ºäº†å¦‚ä½•åœ¨æ²¡æœ‰äººå·¥æ ‡æ³¨å’Œè·¨æ¨¡æ€ä¿¡å·çš„æƒ…å†µä¸‹ï¼Œä»…ä»å›¾åƒæœ¬èº«ä¸­æŒ–æ˜å‡ºæå…¶ä¸°å¯Œå’Œé²æ£’çš„è§†è§‰ä¿¡æ¯ã€‚DINOçš„æå‡ºï¼Œæ˜¯è‡ªç›‘ç£è§†è§‰å­¦ä¹ é¢†åŸŸçš„ä¸€æ¬¡å…³é”®çªç ´ã€‚å®ƒå¼•å…¥äº†ä¸€ç§åä¸ºâ€œè‡ªè’¸é¦â€ï¼ˆSelf-Distillationï¼‰çš„åˆ›æ–°è®­ç»ƒæœºåˆ¶ï¼Œå·§å¦™åœ°åˆ©ç”¨äº†çŸ¥è¯†è’¸é¦çš„æ€æƒ³ï¼Œä½†æ— éœ€ä¸€ä¸ªé¢„å…ˆè®­ç»ƒå¥½çš„â€œæ•™å¸ˆâ€æ¨¡å‹[[26](https://towardsdatascience.com/dino-a-foundation-model-for-computer-vision-4cb08e821b18)]ã€‚DINOçš„æ¶æ„åŒ…å«ä¸¤ä¸ªç»“æ„å®Œå…¨ç›¸åŒä½†å‚æ•°ä¸åŒçš„ç½‘ç»œï¼šä¸€ä¸ªâ€œå­¦ç”Ÿâ€ç½‘ç»œå’Œä¸€ä¸ªâ€œæ•™å¸ˆâ€ç½‘ç»œã€‚å­¦ç”Ÿç½‘ç»œçš„å‚æ•°é€šè¿‡æ¢¯åº¦ä¸‹é™è¿›è¡Œæ›´æ–°ï¼Œè€Œæ•™å¸ˆç½‘ç»œçš„å‚æ•°åˆ™é€šè¿‡å­¦ç”Ÿç½‘ç»œå‚æ•°çš„æŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼ˆExponential Moving Average, EMAï¼‰è¿›è¡Œå¹³æ»‘æ›´æ–°ã€‚è¿™ç§åŠ¨é‡ç¼–ç å™¨ï¼ˆMomentum Encoderï¼‰çš„è®¾è®¡ä½¿å¾—æ•™å¸ˆç½‘ç»œçš„æ›´æ–°æ›´åŠ ç¨³å®šï¼Œèƒ½å¤Ÿä¸ºå­¦ç”Ÿç½‘ç»œæä¾›æ›´ä¸€è‡´ã€æ›´å¯é çš„æŒ‡å¯¼ä¿¡å·ã€‚

DINOçš„è®­ç»ƒè¿‡ç¨‹æ˜¯ä¸€ä¸ªç»å…¸çš„â€œåœ¨çº¿è’¸é¦â€è¿‡ç¨‹ã€‚é¦–å…ˆï¼Œå¯¹åŒä¸€å¼ è¾“å…¥å›¾åƒï¼Œåº”ç”¨ä¸¤ç§ä¸åŒçš„æ•°æ®å¢å¼ºï¼ˆData Augmentationï¼‰ç­–ç•¥ï¼Œç”Ÿæˆä¸¤ä¸ªä¸åŒçš„â€œè§†å›¾â€ï¼ˆViewsï¼‰ã€‚è¿™ä¸¤ä¸ªè§†å›¾è¢«åˆ†åˆ«é€å…¥å­¦ç”Ÿç½‘ç»œå’Œæ•™å¸ˆç½‘ç»œï¼Œå¾—åˆ°ä¸¤ä¸ªè¾“å‡ºç‰¹å¾ã€‚DINOçš„æ ¸å¿ƒç›®æ ‡æ˜¯æœ€å°åŒ–è¿™ä¸¤ä¸ªè¾“å‡ºåˆ†å¸ƒåœ¨ç‰¹å®šç»´åº¦ï¼ˆé€šå¸¸æ˜¯[class]æ ‡è®°çš„è¾“å‡ºï¼‰ä¸Šçš„KLæ•£åº¦ï¼ˆKullbackâ€“Leibler Divergenceï¼‰ã€‚æ¢å¥è¯è¯´ï¼Œå­¦ç”Ÿç½‘ç»œè¢«è®­ç»ƒå»æ¨¡ä»¿æ•™å¸ˆç½‘ç»œåœ¨ç»è¿‡ä¸åŒæ•°æ®å¢å¼ºåçš„å›¾åƒè§†å›¾ä¸Šäº§ç”Ÿçš„è¾“å‡ºã€‚è¿™ç§è‡ªå¯¹æ¯”æœºåˆ¶è¿«ä½¿æ¨¡å‹å­¦ä¹ åˆ°é‚£äº›åœ¨ä¸åŒè§†è§’ã€ä¸åŒå…‰ç…§ã€ä¸åŒé®æŒ¡æ¡ä»¶ä¸‹éƒ½ä¿æŒä¸å˜çš„æ ¸å¿ƒå›¾åƒç‰¹å¾ï¼Œä»è€Œå­¦ä¹ åˆ°é«˜åº¦ä¸å˜å’Œé²æ£’çš„è§†è§‰è¡¨ç¤º[[23](https://www.emergentmind.com/topics/dinov2-based-approaches)]ã€‚DINOçš„ä¸€ä¸ªéå‡¡ç‰¹æ€§æ˜¯ï¼Œå®ƒèƒ½å¤Ÿè‡ªå‘åœ°åœ¨æ²¡æœ‰ä»»ä½•ç›‘ç£ä¿¡å·çš„æƒ…å†µä¸‹ï¼Œå­¦ä¹ åˆ°å›¾åƒçš„è¯­ä¹‰åˆ†å‰²ï¼ˆSemantic Segmentationï¼‰ã€‚ç ”ç©¶è€…å‘ç°ï¼Œä»…ä»…é€šè¿‡DINOè¿›è¡Œé¢„è®­ç»ƒï¼ŒViTæ¨¡å‹çš„ä¸åŒâ€œå¤´â€ï¼ˆHeadï¼‰å°±ä¼šè‡ªåŠ¨å…³æ³¨åˆ°å›¾åƒä¸­çš„ä¸åŒç‰©ä½“ï¼Œå¹¶ä¸”å…¶æœ€åä¸€ä¸ªæ³¨æ„åŠ›å›¾ï¼ˆAttention Mapï¼‰èƒ½å¤Ÿæ¸…æ™°åœ°å‹¾å‹’å‡ºç‰©ä½“çš„è¾¹ç•Œã€‚è¿™ä¸€â€œæ¶Œç°å±æ€§â€ï¼ˆEmergent Propertyï¼‰è¯æ˜äº†DINOå­¦åˆ°çš„è¡¨ç¤ºä¸ä»…ä»…æ˜¯åƒç´ çº§çš„ç»Ÿè®¡è§„å¾‹ï¼Œè€Œæ˜¯å…·æœ‰æ·±åˆ»è¯­ä¹‰ç†è§£èƒ½åŠ›çš„ç‰¹å¾ã€‚

åœ¨DINOçš„åŸºç¡€ä¸Šï¼ŒDINOv2è¿›ä¸€æ­¥å°†è¿™ä¸€æ€æƒ³æ¨å‘äº†æè‡´ï¼Œæ—¨åœ¨æ„å»ºä¸€ä¸ªçœŸæ­£æ„ä¹‰ä¸Šçš„è§†è§‰åŸºç¡€æ¨¡å‹ï¼ˆVision Foundation Modelï¼‰[[20](https://arxiv.org/abs/2304.07193)]ã€‚DINOv2çš„æ ¸å¿ƒæ´å¯Ÿæ˜¯ï¼Œè‡ªç›‘ç£æ–¹æ³•çš„è´¨é‡é«˜åº¦ä¾èµ–äºè®­ç»ƒæ•°æ®çš„è§„æ¨¡å’Œå¤šæ ·æ€§ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶è€…ä»¬ç²¾å¿ƒç­–åˆ’å¹¶æ„å»ºäº†ä¸€ä¸ªåŒ…å«1.42äº¿å¼ å›¾åƒçš„ã€ç»è¿‡é«˜åº¦ç­›é€‰å’Œæ•´ç†çš„ç§æœ‰æ•°æ®é›†ã€‚é€šè¿‡åœ¨è¿™ä¸ªæµ·é‡ä¸”å¤šæ ·åŒ–çš„æ•°æ®é›†ä¸Šè¿›è¡ŒDINOé£æ ¼çš„é¢„è®­ç»ƒï¼ŒDINOv2å­¦ä¹ åˆ°äº†æå…¶å¼ºå¤§å’Œé€šç”¨çš„è§†è§‰ç‰¹å¾ã€‚è¿™äº›ç‰¹å¾çš„å¼ºå¤§ä¹‹å¤„åœ¨äºï¼Œå®ƒä»¬å¯ä»¥ç›´æ¥ç”¨äºå„ç§ä¸‹æ¸¸è®¡ç®—æœºè§†è§‰ä»»åŠ¡ï¼ˆå¦‚åˆ†ç±»ã€åˆ†å‰²ã€ç›®æ ‡æ£€æµ‹ã€æ·±åº¦ä¼°è®¡ç­‰ï¼‰ï¼Œè€Œæ— éœ€è¿›è¡Œå¾®è°ƒï¼Œä»…éœ€åœ¨è¿™äº›ä»»åŠ¡çš„ç‰¹å¾ä¹‹ä¸Šè®­ç»ƒä¸€ä¸ªç®€å•çš„çº¿æ€§åˆ†ç±»å™¨å³å¯å–å¾—é¡¶å°–æ€§èƒ½[[22](https://github.com/facebookresearch/dinov2)]ã€‚DINOv2çš„æˆåŠŸæ ‡å¿—ç€ï¼Œçº¯è§†è§‰çš„è‡ªç›‘ç£é¢„è®­ç»ƒå·²ç»èƒ½å¤Ÿäº§ç”Ÿä¸CLIPç­‰å¤šæ¨¡æ€æ¨¡å‹ç›¸åª²ç¾ï¼Œç”šè‡³åœ¨æŸäº›çº¯è§†è§‰ä»»åŠ¡ä¸Šæ›´ä¼˜çš„é€šç”¨è¡¨ç¤ºï¼Œä¸ºæ„å»ºä¸ä¾èµ–è¯­è¨€çš„è§†è§‰â€œå¤§è„‘â€æä¾›äº†å¯èƒ½ã€‚

ä¸DINOçš„è‡ªè’¸é¦å¹¶è¡Œå‘å±•çš„ï¼Œæ˜¯å¦ä¸€æ¡ä»¥æ©ç å›¾åƒå»ºæ¨¡ï¼ˆMasked Image Modeling, MIMï¼‰ä¸ºæ ¸å¿ƒçš„è·¯çº¿ï¼Œå…¶ç›´æ¥ç»§æ‰¿äº†BERTçš„â€œå¡«ç©ºâ€æ€æƒ³ã€‚è¿™æ¡è·¯çº¿çš„æ—©æœŸæ¢ç´¢è€…åŒ…æ‹¬BEiTï¼ˆBERT Pre-Training of Image Transformersï¼‰å’ŒMAEï¼ˆMasked AutoEncodersï¼‰[[50](https://arxiv.org/abs/2106.08254)]ã€‚BEiTæ˜¯ç¬¬ä¸€ä¸ªæˆåŠŸå°†BERTèŒƒå¼åº”ç”¨äºViTçš„æ¨¡å‹ï¼Œå®ƒæ²¡æœ‰ç›´æ¥é¢„æµ‹è¢«é®ç›–å›¾åƒå—çš„åƒç´ å€¼ï¼Œè€Œæ˜¯é¢„æµ‹è¿™äº›å›¾åƒå—çš„â€œè§†è§‰ä»¤ç‰Œâ€ï¼ˆVisual Tokensï¼‰[[54](https://medium.com/@deepsiya10/day-10-beit-bert-meets-vision-ad381757a71d)]ã€‚è¿™äº›è§†è§‰ä»¤ç‰Œæ˜¯é€šè¿‡ä¸€ä¸ªç¦»çº¿è®­ç»ƒçš„ã€ç¦»æ•£çš„ç æœ¬ï¼ˆCodebookï¼‰ï¼ˆå¦‚dVAEï¼‰å°†å›¾åƒå—é‡åŒ–å¾—åˆ°çš„ã€‚é¢„æµ‹ç¦»æ•£çš„ä»¤ç‰Œæ¯”é¢„æµ‹è¿ç»­çš„åƒç´ å€¼è¢«è®¤ä¸ºæ˜¯ä¸€ä¸ªæ›´é«˜çº§ã€æ›´å…·è¯­ä¹‰æ€§çš„ä»»åŠ¡ã€‚è€ŒMAEåˆ™æå‡ºäº†ä¸€ç§æå…¶é«˜æ•ˆçš„éå¯¹ç§°ç¼–ç å™¨-è§£ç å™¨è®¾è®¡[[45](https://www.emergentmind.com/topics/masked-autoencoder-mae-pretraining-strategy)]ã€‚å®ƒåªå°†ä¸€å°éƒ¨åˆ†ï¼ˆå¦‚25%ï¼‰çš„å¯è§å›¾åƒå—é€å…¥ç¼–ç å™¨è¿›è¡Œç‰¹å¾æå–ï¼Œç„¶åå°†ç¼–ç å™¨çš„è¾“å‡ºä¸è¢«é®ç›–çš„å›¾åƒå—çš„ä½ç½®ä¿¡æ¯æ‹¼æ¥åœ¨ä¸€èµ·ï¼Œé€å…¥ä¸€ä¸ªè½»é‡çº§çš„è§£ç å™¨æ¥é‡å»ºåŸå§‹å›¾åƒ[[48](https://sh-tsang.medium.com/review-masked-autoencoders-are-scalable-vision-learners-b7c42910f7b4)]ã€‚è¿™ç§è®¾è®¡å¤§å¤§é™ä½äº†é¢„è®­ç»ƒçš„è®¡ç®—æˆæœ¬ï¼Œä½¿å¾—è®­ç»ƒè¶…å¤§è§„æ¨¡çš„ViTæ¨¡å‹æˆä¸ºå¯èƒ½ã€‚

iBOTï¼ˆImage BERT Pre-Training with Online Tokenizerï¼‰åˆ™å¯ä»¥çœ‹ä½œæ˜¯BEiTå’ŒDINOæ€æƒ³çš„é›†å¤§æˆè€…ï¼Œå®ƒå°†æ©ç å»ºæ¨¡ä¸è‡ªè’¸é¦æœºåˆ¶å·§å¦™åœ°èåˆåœ¨ä¸€èµ·[[10](https://arxiv.org/abs/2111.07832)]ã€‚iBOTçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶â€œåœ¨çº¿ä»¤ç‰Œå™¨â€ï¼ˆOnline Tokenizerï¼‰ã€‚ä¸BEiTä½¿ç”¨ç¦»çº¿ã€å›ºå®šçš„ç æœ¬ä¸åŒï¼ŒiBOTçš„ä»¤ç‰Œå™¨æ˜¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸å­¦ç”Ÿç½‘ç»œä¸€èµ·ç«¯åˆ°ç«¯å­¦ä¹ çš„ã€‚è¿™ä¸ªä»¤ç‰Œå™¨æœ¬è´¨ä¸Šå°±æ˜¯ä¸€ä¸ªç›®æ ‡ç½‘ç»œï¼Œå…¶ç»“æ„ä¸å­¦ç”Ÿç½‘ç»œçš„ç¼–ç å™¨ç±»ä¼¼ã€‚iBOTçš„è®­ç»ƒè¿‡ç¨‹åŒ…å«ä¸¤ä¸ªå¹¶è¡Œçš„ç›®æ ‡ï¼šç¬¬ä¸€ä¸ªç›®æ ‡æ˜¯ç»å…¸çš„æ©ç å›¾åƒå»ºæ¨¡ã€‚å­¦ç”Ÿç½‘ç»œæ¥æ”¶è¢«é«˜åº¦é®ç›–ï¼ˆå¦‚é®ç›–75%ï¼‰çš„å›¾åƒï¼Œå¹¶å°è¯•é¢„æµ‹è¢«é®ç›–åŒºåŸŸçš„è§†è§‰ä»¤ç‰Œï¼Œè€Œè¿™äº›ä»¤ç‰Œæ˜¯ç”±æ•™å¸ˆç½‘ç»œï¼ˆä½œä¸ºåœ¨çº¿ä»¤ç‰Œå™¨ï¼‰ä»åŸå§‹çš„ã€æœªé®ç›–çš„å›¾åƒä¸­ç”Ÿæˆçš„ã€‚ç¬¬äºŒä¸ªç›®æ ‡æ˜¯DINOå¼çš„è‡ªè’¸é¦ç›®æ ‡ï¼Œå³è®©å­¦ç”Ÿç½‘ç»œåœ¨å…¨å±€å›¾åƒå±‚é¢ï¼ˆå¦‚[class]æ ‡è®°çš„è¾“å‡ºï¼‰æ¨¡ä»¿æ•™å¸ˆç½‘ç»œçš„è¾“å‡º[[11](https://sh-tsang.medium.com/brief-review-ibot-image-bert-pre-training-with-online-tokenizer-85c32e47fee6)]ã€‚é€šè¿‡è¿™ç§åŒé‡ç›®æ ‡çš„è”åˆä¼˜åŒ–ï¼ŒiBOTåŒæ—¶è·å¾—äº†ä¸¤æ–¹é¢çš„å¥½å¤„ï¼šæ©ç å»ºæ¨¡è¿«ä½¿æ¨¡å‹å­¦ä¹ å›¾åƒçš„å±€éƒ¨ç»†èŠ‚å’Œç»“æ„ä¿¡æ¯ï¼Œè€Œè‡ªè’¸é¦åˆ™ä¿è¯äº†æ¨¡å‹å­¦ä¹ åˆ°çš„å…¨å±€è¡¨ç¤ºçš„é²æ£’æ€§å’Œä¸€è‡´æ€§ã€‚iBOTçš„æˆåŠŸè¯æ˜äº†ï¼Œå°†ä¸åŒçš„è‡ªç›‘ç£å­¦ä¹ èŒƒå¼è¿›è¡Œæœ‰æœºç»“åˆï¼Œèƒ½å¤Ÿäº§ç”Ÿ1+1>2çš„æ•ˆæœï¼Œä»è€Œå­¦ä¹ åˆ°æ›´å…¨é¢ã€æ›´å¼ºå¤§çš„è§†è§‰è¡¨ç¤ºã€‚ä»DINOçš„è‡ªè’¸é¦åˆ°iBOTçš„åœ¨çº¿ä»¤ç‰Œå™¨ä¸æ©ç å»ºæ¨¡çš„èåˆï¼Œæˆ‘ä»¬çœ‹åˆ°äº†ä¸€æ¡æ¸…æ™°çš„æ¼”è¿›è·¯å¾„ï¼šè‡ªç›‘ç£å­¦ä¹ çš„è®¾è®¡å˜å¾—è¶Šæ¥è¶Šç²¾å¯†ï¼Œè¶Šæ¥è¶Šèƒ½å¤Ÿä»æ•°æ®ä¸­æ¦¨å–å‡ºæœ‰ä»·å€¼çš„ç›‘ç£ä¿¡å·ï¼Œæœ€ç»ˆç›®æ ‡æ˜¯æ„å»ºä¸€ä¸ªèƒ½å¤Ÿåƒäººç±»ä¸€æ ·ï¼Œä»…é€šè¿‡è§‚å¯Ÿä¸–ç•Œå°±èƒ½æ·±åˆ»ç†è§£å…¶å†…åœ¨è§„å¾‹çš„æ™ºèƒ½ç³»ç»Ÿã€‚

## èåˆä¸å±•æœ›ï¼šè¿ˆå‘ç»Ÿä¸€çš„è§†è§‰åŸºç¡€æ¨¡å‹

éšç€Vision Transformerï¼ˆViTï¼‰æ¶æ„çš„ç¡®ç«‹ï¼Œä»¥åŠCLIPã€DINOå’ŒiBOTç­‰é¢„è®­ç»ƒèŒƒå¼çš„è“¬å‹ƒå‘å±•ï¼Œè§†è§‰å¤§æ¨¡å‹çš„ç ”ç©¶è¿›å…¥äº†ä¸€ä¸ªç™¾å®¶äº‰é¸£çš„é»„é‡‘æ—¶ä»£ã€‚ç„¶è€Œï¼Œåœ¨ç»å†äº†åˆæœŸçš„çˆ†ç‚¸å¼åˆ›æ–°åï¼Œä¸€ä¸ªè‡ªç„¶çš„é—®é¢˜æµ®å‡ºæ°´é¢ï¼šè¿™äº›çœ‹ä¼¼ä¸åŒã€å„æœ‰æ‰€é•¿çš„é¢„è®­ç»ƒæ–¹æ³•ï¼Œæ˜¯å¦å­˜åœ¨æŸç§å†…åœ¨çš„è”ç³»ï¼Œèƒ½å¦è¢«èåˆæˆä¸€ä¸ªæ›´å¼ºå¤§ã€æ›´ç»Ÿä¸€çš„æ¡†æ¶ï¼Ÿå¯¹è¿™ä¸€é—®é¢˜çš„æ¢ç´¢ï¼Œå¼•é¢†ç€è§†è§‰é¢„è®­ç»ƒé¢†åŸŸå‘ç€æ›´é«˜å±‚æ¬¡çš„é›†æˆåŒ–å’Œé€šç”¨åŒ–è¿ˆè¿›ï¼Œå…¶æœ€ç»ˆç›®æ ‡æ˜¯æ„å»ºèƒ½å¤Ÿèƒœä»»ä»»ä½•è§†è§‰ä»»åŠ¡çš„â€œè§†è§‰åŸºç¡€æ¨¡å‹â€ï¼ˆVision Foundation Modelï¼‰ã€‚åœ¨è¿™ä¸€èåˆä¸å±•æœ›çš„æµªæ½®ä¸­ï¼ŒEVAï¼ˆExploring the Limits of Masked Visual Representation Learning at Scaleï¼‰ç³»åˆ—æ¨¡å‹çš„å‡ºç°ï¼Œä¸ºæˆ‘ä»¬æ­ç¤ºäº†ä¸€æ¡æå…·å‰æ™¯çš„èåˆè·¯å¾„ï¼Œå®ƒå·§å¦™åœ°æ¡¥æ¥äº†ä»¥CLIPä¸ºä»£è¡¨çš„å¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ ä¸ä»¥iBOTä¸ºä»£è¡¨çš„æ©ç å»ºæ¨¡ä¹‹é—´çš„é¸¿æ²Ÿã€‚

EVAçš„æ ¸å¿ƒæ€æƒ³å¯ä»¥è¢«æ¦‚æ‹¬ä¸ºâ€œç«™åœ¨å·¨äººçš„è‚©è†€ä¸Šâ€ã€‚ç ”ç©¶è€…ä»¬è®¤è¯†åˆ°ï¼ŒåƒCLIPè¿™æ ·é€šè¿‡æµ·é‡å›¾åƒ-æ–‡æœ¬å¯¹é½æ•°æ®é¢„è®­ç»ƒå‡ºçš„æ¨¡å‹ï¼Œå…¶å›¾åƒç¼–ç å™¨å·²ç»å­¦ä¹ åˆ°äº†æå…¶ä¸°å¯Œä¸”ä¸è¯­ä¹‰ç´§å¯†å…³è”çš„è§†è§‰ç‰¹å¾[[64](https://openaccess.thecvf.com/content/CVPR2023/papers/Fang_EVA_Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_CVPR_2023_paper.pdf)]ã€‚è¿™äº›ç‰¹å¾æœ¬èº«å°±æ˜¯ä¸€ç§é«˜è´¨é‡çš„ã€è•´å«è¯­ä¹‰ä¿¡æ¯çš„â€œç›‘ç£ä¿¡å·â€ã€‚é‚£ä¹ˆï¼Œæˆ‘ä»¬èƒ½å¦ç›´æ¥åˆ©ç”¨è¿™äº›å¼ºå¤§çš„ç‰¹å¾ä½œä¸ºæ©ç å»ºæ¨¡çš„é‡å»ºç›®æ ‡å‘¢ï¼Ÿè¿™æ­£æ˜¯EVAæ‰€åšçš„ã€‚EVAé‡‡ç”¨äº†ä¸€ä¸ªç»å…¸çš„ViTä½œä¸ºå…¶éª¨å¹²ç½‘ç»œï¼Œä½†å…¶é¢„è®­ç»ƒä»»åŠ¡å´ä¸å†æ˜¯é¢„æµ‹åƒç´ æˆ–ç¦»æ•£çš„è§†è§‰ä»¤ç‰Œï¼Œè€Œæ˜¯ç›´æ¥é¢„æµ‹è¢«é®ç›–å›¾åƒå—æ‰€å¯¹åº”çš„CLIPå›¾åƒç¼–ç å™¨çš„è¾“å‡ºç‰¹å¾[[67](https://arxiv.org/abs/2211.07636)]ã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨é¢„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒEVAçš„ç¼–ç å™¨æ¥æ”¶ä¸€å¹…è¢«éƒ¨åˆ†é®ç›–çš„å›¾åƒï¼Œå¹¶åŸºäºå¯è§çš„å›¾åƒå—æ¥é¢„æµ‹é‚£äº›è¢«é®ç›–åŒºåŸŸçš„ç‰¹å¾ã€‚è¿™ä¸ªé¢„æµ‹çš„ç›®æ ‡ï¼Œå°±æ˜¯é¢„è®­ç»ƒå¥½çš„CLIPå›¾åƒç¼–ç å™¨åœ¨å¤„ç†å®Œæ•´ã€æœªé®ç›–å›¾åƒæ—¶ï¼Œåœ¨å¯¹åº”ä½ç½®è¾“å‡ºçš„ç‰¹å¾å‘é‡ã€‚

è¿™ç§è®¾è®¡å¸¦æ¥äº†å¤šæ–¹é¢çš„æ·±åˆ»ä¼˜åŠ¿ã€‚é¦–å…ˆï¼Œå®ƒæå¤§åœ°æå‡äº†æ©ç å»ºæ¨¡ä»»åŠ¡çš„è¯­ä¹‰å±‚æ¬¡ã€‚ä¸é‡å»ºåŸå§‹åƒç´ æˆ–ç®€å•çš„ç¦»æ•£ä»¤ç‰Œç›¸æ¯”ï¼Œé‡å»ºCLIPç‰¹å¾æ„å‘³ç€æ¨¡å‹éœ€è¦å­¦ä¹ ç†è§£å’Œé¢„æµ‹é‚£äº›ä¸é«˜çº§æ¦‚å¿µï¼ˆå¦‚ç‰©ä½“ã€å±æ€§ã€åœºæ™¯ï¼‰ç›¸å…³è”çš„è¡¨ç¤ºã€‚è¿™è¿«ä½¿EVAçš„ç¼–ç å™¨ä¸ä»…è¦å­¦ä¹ å›¾åƒçš„ä½çº§çº¹ç†å’Œå½¢çŠ¶ï¼Œæ›´è¦å­¦ä¹ å…¶é«˜å±‚è¯­ä¹‰å†…å®¹ã€‚å…¶æ¬¡ï¼ŒEVAå®ç°äº†çŸ¥è¯†çš„æœ‰æ•ˆè’¸é¦å’Œè¿ç§»ã€‚å®ƒå°†CLIPé€šè¿‡æµ·é‡å¤šæ¨¡æ€æ•°æ®å­¦ä¹ åˆ°çš„å®è´µçŸ¥è¯†ï¼Œä»¥ä¸€ç§é«˜æ•ˆçš„æ–¹å¼â€œè’¸é¦â€åˆ°äº†ä¸€ä¸ªçº¯è§†è§‰çš„ViTæ¨¡å‹ä¸­ã€‚è¿™ä½¿å¾—EVAèƒ½å¤Ÿç»§æ‰¿CLIPå¼ºå¤§çš„å¼€æ”¾è¯æ±‡ç†è§£èƒ½åŠ›å’Œæ³›åŒ–æ€§ï¼ŒåŒæ—¶åˆä¿æŒäº†ViTæ¶æ„çš„ç®€æ´å’Œé«˜æ•ˆã€‚EVAçš„åç»­ç‰ˆæœ¬ï¼Œå¦‚EVA-02ï¼Œè¿›ä¸€æ­¥æ‰©å±•å’Œæ·±åŒ–äº†è¿™ä¸€æ€æƒ³ï¼Œé€šè¿‡åœ¨æ›´å¤§è§„æ¨¡çš„æ•°æ®å’Œæ›´å…ˆè¿›çš„CLIPæ•™å¸ˆæ¨¡å‹ï¼ˆå¦‚EVA-CLIPï¼‰ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œå–å¾—äº†æ›´åŠ å“è¶Šçš„æ€§èƒ½ï¼Œè¯æ˜äº†è¿™ä¸€èŒƒå¼çš„å¼ºå¤§å¯æ‰©å±•æ€§[[62](https://www.sciencedirect.com/science/article/abs/pii/S0262885624002762)]ã€‚EVAçš„æˆåŠŸï¼Œæ ‡å¿—ç€è§†è§‰é¢„è®­ç»ƒè¿›å…¥äº†ä¸€ä¸ªâ€œåå…ƒå­¦ä¹ â€çš„æ—¶ä»£ï¼šæˆ‘ä»¬ä¸å†ä»…ä»…ä»åŸå§‹æ•°æ®ä¸­å­¦ä¹ ï¼Œè€Œæ˜¯å¼€å§‹ä»å…¶ä»–å·²ç»å¼ºå¤§çš„é¢„è®­ç»ƒæ¨¡å‹ä¸­å­¦ä¹ ï¼Œå½¢æˆäº†ä¸€ç§æ¨¡å‹ä¹‹é—´çŸ¥è¯†ä¼ æ‰¿å’Œè¿­ä»£çš„è‰¯æ€§å¾ªç¯ã€‚

å±•æœ›æœªæ¥ï¼Œè§†è§‰å¤§æ¨¡å‹åŠå…¶é¢„è®­ç»ƒæ–¹å¼çš„å‘å±•æ­£æœç€å‡ ä¸ªæ¸…æ™°è€Œæ¿€åŠ¨äººå¿ƒçš„æ–¹å‘æ¼”è¿›ã€‚**é¦–å…ˆæ˜¯æ¨¡å‹çš„æŒç»­è§„æ¨¡åŒ–ã€‚** æ— è®ºæ˜¯DINOv2é€šè¿‡æ‰©å¤§æ•°æ®é›†å®ç°çš„â€œæ•°æ®è§„æ¨¡å®šå¾‹â€ï¼Œè¿˜æ˜¯EVAé€šè¿‡è’¸é¦CLIPå®ç°çš„â€œçŸ¥è¯†è§„æ¨¡å®šå¾‹â€ï¼Œéƒ½å°è¯äº†â€œè§„æ¨¡å³æ™ºèƒ½â€è¿™ä¸€è¶‹åŠ¿ã€‚æœªæ¥ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°å‚æ•°é‡è¾¾åˆ°æ•°åäº¿ç”šè‡³ä¸Šç™¾äº¿çš„è§†è§‰æ¨¡å‹ï¼Œå®ƒä»¬å°†åœ¨æ›´åŠ åºå¤§å’Œå¤šæ ·çš„æ•°æ®ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œä»è€Œè·å¾—å‰æ‰€æœªæœ‰çš„è§†è§‰è®¤çŸ¥èƒ½åŠ›ã€‚**å…¶æ¬¡æ˜¯å¤šæ¨¡æ€èåˆçš„æ·±åŒ–ã€‚** CLIPå¼€åˆ›äº†å›¾åƒä¸æ–‡æœ¬çš„å¯¹é½ï¼Œè€Œæœªæ¥çš„æ¨¡å‹å°†è‡´åŠ›äºèåˆæ›´å¤šæ¨¡æ€çš„ä¿¡æ¯ï¼Œå¦‚éŸ³é¢‘ã€è§†é¢‘ã€3Dã€ä¼ æ„Ÿå™¨æ•°æ®ç­‰ã€‚ä¾‹å¦‚ï¼ŒNeRF-MAEå·²ç»å¼€å§‹æ¢ç´¢å°†æ©ç å»ºæ¨¡æ€æƒ³åº”ç”¨äº3Dç¥ç»åœºï¼ˆNeural Radiance Fields, NeRFï¼‰çš„é¢„è®­ç»ƒï¼Œè¿™é¢„ç¤ºç€è‡ªç›‘ç£å­¦ä¹ å°†çªç ´2Då›¾åƒçš„ç•Œé™ï¼Œèµ°å‘å¯¹ä¸‰ç»´åŠ¨æ€ä¸–ç•Œçš„ç†è§£[[40](https://arxiv.org/abs/2404.01300)]ã€‚**ç¬¬ä¸‰æ˜¯é¢„è®­ç»ƒèŒƒå¼çš„ç»Ÿä¸€ä¸è‡ªåŠ¨åŒ–ã€‚** ä»DINOçš„è‡ªè’¸é¦ï¼Œåˆ°iBOTçš„åœ¨çº¿ä»¤ç‰Œå™¨ï¼Œå†åˆ°EVAçš„ç‰¹å¾é‡å»ºï¼Œæˆ‘ä»¬çœ‹åˆ°é¢„è®­ç»ƒç›®æ ‡çš„è®¾è®¡å˜å¾—è¶Šæ¥è¶Šå¤æ‚å’Œç²¾å·§ã€‚æœªæ¥çš„ä¸€ä¸ªé‡è¦æ–¹å‘æ˜¯å¼€å‘èƒ½å¤Ÿè‡ªåŠ¨å‘ç°æˆ–ç”Ÿæˆæœ€ä¼˜é¢„è®­ç»ƒä»»åŠ¡çš„ç®—æ³•ï¼Œè®©æ¨¡å‹èƒ½å¤Ÿæ ¹æ®æ•°æ®å’Œç›®æ ‡ï¼Œè‡ªé€‚åº”åœ°è®¾è®¡å…¶å­¦ä¹ ç­–ç•¥ã€‚**æœ€åï¼Œä¹Ÿæ˜¯æœ€é‡è¦çš„ï¼Œæ˜¯å‘é€šç”¨äººå·¥æ™ºèƒ½ï¼ˆArtificial General Intelligence, AGIï¼‰çš„è¿ˆè¿›ã€‚** è§†è§‰åŸºç¡€æ¨¡å‹æ­£é€æ¸æˆä¸ºæ„å»ºAGIä¸å¯æˆ–ç¼ºçš„â€œçœ¼ç›â€å’Œâ€œè§†è§‰çš®å±‚â€ã€‚å®ƒä»¬æä¾›çš„ä¸ä»…ä»…æ˜¯åƒç´ è¯†åˆ«èƒ½åŠ›ï¼Œè€Œæ˜¯ä¸€ç§å¯¹ä¸–ç•Œçš„ç»“æ„åŒ–ã€è¯­ä¹‰åŒ–çš„ç†è§£ã€‚è¿™ç§ç†è§£æ˜¯æœºå™¨äººä¸ç¯å¢ƒäº¤äº’ã€æ™ºèƒ½ä½“è¿›è¡Œå¤æ‚æ¨ç†å’Œè§„åˆ’çš„åŸºç¡€ã€‚ä»ViTçš„æ¶æ„é©æ–°ï¼Œåˆ°CLIPçš„è·¨æ¨¡æ€å¯¹é½ï¼Œå†åˆ°DINOã€iBOTå’ŒEVAåœ¨è‡ªç›‘ç£é¢†åŸŸçš„æ·±åº¦æ¼”åŒ–ï¼Œæˆ‘ä»¬è§è¯çš„ä¸ä»…ä»…æ˜¯ä¸€ç³»åˆ—æ¨¡å‹çš„è¿­ä»£ï¼Œæ›´æ˜¯ä¸€åœºå…³äºå¦‚ä½•è®©æœºå™¨â€œçœ‹è§â€å¹¶â€œç†è§£â€è¿™ä¸ªä¸–ç•Œçš„è®¤çŸ¥é©å‘½ã€‚è¿™åœºé©å‘½è¿œæœªç»“æŸï¼Œå®ƒæ­£å¼•é¢†ç€æˆ‘ä»¬å‘ç€æ„å»ºçœŸæ­£å…·å¤‡é€šç”¨è§†è§‰æ™ºèƒ½çš„ç»ˆæç›®æ ‡ï¼Œåšå®šè€Œæœ‰åŠ›åœ°è¿ˆè¿›ã€‚

# å‚è€ƒæ–‡çŒ®

[0] Vision Transformer: What It Is & How It Works [2024 Guide]. https://www.v7labs.com/blog/vision-transformer-guide.

[1] Pre-training of Lightweight Vision Transformers on Small. https://arxiv.org/abs/2402.03752.

[2] Vision transformer-based visual language understanding. https://www.sciencedirect.com/science/article/pii/S1110016824004873.

[3] Accelerating Augmentation Invariance Pretraining. https://neurips.cc/virtual/2024/poster/94817.

[4] Evaluation of effectiveness of pre-training method in chest. https://www.tandfonline.com/doi/full/10.1080/21681163.2024.2345823.

[5] What is a Vision Transformer (ViT)? Complete Guide 2026. https://www.articsledge.com/post/vision-transformer-vit.

[6] Domain-Specific Vision Transformer Pre-Training with. https://dl.acm.org/doi/10.1145/3704137.3704168.

[7] Vision Transformers (ViT) in Image Recognition. https://viso.ai/deep-learning/vision-transformer-vit.

[8] An Explanation of the Vision Transformer (ViT) Paper. https://medium.com/codex/an-explanation-of-the-vision-transformer-vit-paper-8cdd399741aa.

[9] lucidrains/vit-pytorch: Implementation of Vision Transformer. https://github.com/lucidrains/vit-pytorch.

[10] iBOT: Image BERT Pre-Training with Online Tokenizer. https://arxiv.org/abs/2111.07832.

[11] iBOT: Image BERT Pre-Training with Online Tokenizer | by Sik. https://sh-tsang.medium.com/brief-review-ibot-image-bert-pre-training-with-online-tokenizer-85c32e47fee6.

[12] iBOT: Image BERT Pre-Training with Online Tokenizer. https://huggingface.co/papers/2111.07832.

[13] bytedance/ibot: iBOT :robot:: Image BERT Pre-Training with. https://github.com/bytedance/ibot.

[14] [PDF] iBOT: Image BERT Pre-Training with Online Tokenizer. https://www.semanticscholar.org/paper/iBOT%3A-Image-BERT-Pre-Training-with-Online-Tokenizer-Zhou-Wei/9653c070724e44f023e8cc3ec79f0b9e6d59480d.

[15] IBOT ImageBertPreTrainingWithOnlineTokenizer | PDF. https://www.scribd.com/document/835721965/IBOT-ImageBertPreTrainingWithOnlineTokenizer.

[16] Self-distillation improves self-supervised learning for DNA. https://www.sciencedirect.com/science/article/pii/S0893608024009079.

[17] Enhancing Few-Shot Medical Image Classification with. https://2025.ic-dsp.org/wp-content/uploads/2025/05/2025156473-1.pdf.

[18] Abstract. https://arxiv.org/html/2601.11719v1.

[19] SSL with Vision Transformers. https://rohitbandaru.github.io/blog/SSL-with-Vision-Transformers.

[20] [2304.07193] DINOv2: Learning Robust Visual Features. https://arxiv.org/abs/2304.07193.

[21] Foundation vision models in agriculture: DINOv2, LoRA. https://www.sciencedirect.com/science/article/abs/pii/S0168169925010063.

[22] PyTorch code and models for the DINOv2 self-supervised. https://github.com/facebookresearch/dinov2.

[23] DINOv2-Based Approaches Overview. https://www.emergentmind.com/topics/dinov2-based-approaches.

[24] DINOv2: Self-supervised Learning Model Explained. https://encord.com/blog/dinov2-self-supervised-learning-explained.

[25] Self-Distillation with No Labels (DINO) & DINOV2 - Jehill Parikh. https://jehillparikh.medium.com/improved-image-encoding-using-transformers-self-distillation-with-no-labels-dino-dinov2-79ac5b6cac06.

[26] DINO - A Foundation Model for Computer Vision. https://towardsdatascience.com/dino-a-foundation-model-for-computer-vision-4cb08e821b18.

[27] Examining vision foundation models for classification and. https://www.aanda.org/articles/aa/full_html/2025/11/aa53691-25/aa53691-25.html.

[28] Learning EEG Foundation Models via Hierarchical Self-. https://papers.miccai.org/miccai-2025/paper/3347_paper.pdf.

[29] Accessing Vision Foundation Models via ImageNet-1K. https://openreview.net/forum?id=LC6ZtQV6u2.

[30] CLIP: Connecting text and images. https://openai.com/index/clip.

[31] Contrastive Language-Image Pre-training. https://en.wikipedia.org/wiki/Contrastive_Language-Image_Pre-training.

[32] openai/CLIP. https://github.com/openai/CLIP.

[33] Learning Transferable Visual Models From Natural. https://arxiv.org/abs/2103.00020.

[34] Building a Tiny CLIP: Contrastive Image-Text Learning. https://medium.com/@varun_54675/building-a-tiny-clip-contrastive-image-text-learning-from-scratch-0ca31bf40c65.

[35] A History of CLIP Model Training Data Advances. https://voxel51.com/blog/a-history-of-clip-model-training-data-advances.

[36] CLIP: Contrastive Languageâ€“Image Pre-Training. https://viso.ai/deep-learning/clip-machine-learning.

[37] CLIP by Hand âœï¸ - by Prof. Tom Yeh. https://www.byhand.ai/p/clip.

[38] Training a CLIP Model from Scratch for Text-to-Image. https://learnopencv.com/clip-model.

[39] CLIP Contrastive Languageâ€“Image Pre-Training Model. https://blog.roboflow.com/openai-clip.

[40] NeRF-MAE: Masked AutoEncoders for Self-Supervised 3D. https://arxiv.org/abs/2404.01300.

[41] Masked Autoencoders are Secretly Efficient Learners. https://ieeexplore.ieee.org/document/10677918.

[42] Efficient MAE Towards Large-Scale Vision Transformers. https://openaccess.thecvf.com/content/WACV2024/html/Han_Efficient_MAE_Towards_Large-Scale_Vision_Transformers_WACV_2024_paper.html.

[43] How Effective is Pre-training of Large Masked. https://bmva-archive.org.uk/bmvc/2024/workshops/MVEO/paper5.pdf.

[44] Irrelevant Patch-Masked Autoencoders for Enhancing. https://www.sciencedirect.com/science/article/abs/pii/S0950705124015703.

[45] MAE Pretraining Strategy. https://www.emergentmind.com/topics/masked-autoencoder-mae-pretraining-strategy.

[46] Self-Guided Masked Autoencoder - NIPS. https://proceedings.neurips.cc/paper_files/paper/2024/file/6c4a1a3cbe70ef36d7d6332166bba77d-Paper-Conference.pdf.

[47] Self Pre-Training with Masked Autoencoders for Medical. https://bmi.stonybrookmedicine.edu/node/865.

[48] Review â€” Masked Autoencoders Are Scalable Vision Learners. https://sh-tsang.medium.com/review-masked-autoencoders-are-scalable-vision-learners-b7c42910f7b4.

[49] NeRF-MAE: Masked AutoEncoders for Self-Supervised 3D. https://nerf-mae.github.io.

[50] BEiT: BERT Pre-Training of Image Transformers. https://arxiv.org/abs/2106.08254.

[51] A Mix-and-Mask Approach to Self-Supervised Image Pretraining. https://cs231n.stanford.edu/2024/papers/a-mix-and-mask-approach-to-self-supervised-image-pretraining.pdf.

[52] BEiT. https://huggingface.co/docs/transformers/en/model_doc/beit.

[53] BEiT v2: Masked Image Modeling with Vector-Quantized. https://www.semanticscholar.org/paper/BEiT-v2%3A-Masked-Image-Modeling-with-Visual-Peng-Dong/599be9043ef3571f65758cf36e184c9dc1781baf.

[54] ğŸ“¦ Day 10 â€” BEiT: BERT Meets Vision | by Deepali Mishra. https://medium.com/@deepsiya10/day-10-beit-bert-meets-vision-ad381757a71d.

[55] BEiT v2: Masked Image Modeling with Vector-Quantized. https://www.researchgate.net/publication/362693900_BEiT_v2_Masked_Image_Modeling_with_Vector-Quantized_Visual_Tokenizers.

[56] [22.08] BEiT v2. https://docsaid.org/en/papers/vision-transformers/beit-v2.

[57] Medicinal plant recognition based on Vision Transformer. https://www.sciencedirect.com/science/article/pii/S187705092400351X.

[58] Masked Channel Modeling Enables Vision Transformers to. https://pmc.ncbi.nlm.nih.gov/articles/PMC12385973.

[59] Open-Vocabulary Panoptic Segmentation Using BERT Pre. https://arxiv.org/abs/2412.18917.

[60] arXiv:2402.04252v1 [cs.CV] 6 Feb 2024. https://arxiv.org/pdf/2402.04252.

[61] EVA: Exploring the Limits of Masked Visual Representation. https://www.researchgate.net/publication/373309883_EVA_Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale.

[62] EVA-02: A visual representation for neon genesis. https://www.sciencedirect.com/science/article/abs/pii/S0262885624002762.

[63] EVA: Exploring the Limits of Masked Visual Representation. https://www.connectedpapers.com/main/78281482c1fdad8e167bab39cc9955c73d58ae8f/EVA%3A-Exploring-the-Limits-of-Masked-Visual-Representation-Learning-at-Scale/graph.

[64] EVA: Exploring the Limits of Masked Visual Representation. https://openaccess.thecvf.com/content/CVPR2023/papers/Fang_EVA_Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_CVPR_2023_paper.pdf.

[65] Efficient Vision-Language pre-training via domain-specific. https://aclanthology.org/2024.emnlp-main.454.pdf.

[66] Masked Image Modeling: A Survey. https://link.springer.com/article/10.1007/s11263-025-02524-1.

[67] EVA: Exploring the Limits of Masked Visual Representation. https://arxiv.org/abs/2211.07636.

[68] Improving Visual Comprehension via Token Reconstruction for. https://www.semanticscholar.org/paper/ViCToR%3A-Improving-Visual-Comprehension-via-Token-Xie-Yang/5f4fa6d9c4b97b8e1650195e643a0b4f8c71829e.

[69] Classification Done Right for Vision-Language Pre-Training. https://proceedings.neurips.cc/paper_files/paper/2024/file/aee5298251a418aad89618cf6b5e7ccc-Paper-Conference.pdf.