# 机器学习概述

[【尚硅谷机器学习教程、机器学习从入门到精通】](https://www.bilibili.com/video/BV1BYe4z5E9z/?p=21&share_source=copy_web&vd_source=e65574be5c4ff436d099ae0526b97fd9)

定义：    



# 基本理论

## 机器学习三要素

机器学习的方法一般主要由三部分构成：模型、策略和算法，可以认为：

机 器 学 习 方 法 = 模 型 +  策 略 + 算 法
- 模型（model）：总结数据的内在规律，用数学语言描述的参数系统
- 策略（strategy）：选取最优模型的评价准则，即损失函数和**风险函数**
-  算法（algorithm）：选取最优模型的具体方法（优化算法，例如梯度下降法、Adam、牛顿法）

- **模型是基础（What to learn）**：它界定了我们**能学什么**，决定了系统能力的天花板。没有模型，学习就没有对象和形式。
- **策略是目标（How to evaluate）**：它明确了我们**要学成什么样**，为学习过程提供了明确的优化目标和评价标准。没有策略，我们就无法判断模型的好坏，学习失去方向。
- **算法是途径（How to optimize）**：它提供了**如何学到**的具体路径和工具，将优化目标转化为可执行的计算步骤。没有算法，最优模型只存在于理论中，无法被实际获取。

## 机器学习方法分类
1. 监督学习（Supervised Learning）
	- 回归（线性回归、岭回归、Lasso、多项式回归）
	- 分类（逻辑回归、支持向量机、K近邻、决策树、朴素贝叶斯）
	- 模型评估指标（准确率、精确率、召回率、F1、ROC-AUC、MSE、MAE）
2. 无监督学习（Unsupervised Learning）
	- 聚类（K-Means、层次聚类、DBSCAN、高斯混合模型）
	- 降维（主成分分析 PCA、t-SNE、LDA）
	- 异常检测
	- 关联规则学习（Apriori、FP-Growth）
3. 半监督学习（Semi-supervised Learning）
	- 基本思想与适用场景
	- 常见方法（自训练、协同训练、图半监督）
 4. 强化学习（Reinforcement Learning）
	- 马尔可夫决策过程（MDP）
	- 策略与价值函数
	- Q-learning、Deep Q-Network (DQN)
	- 策略梯度方法（如 REINFORCE、Actor-Critic）
5. 其他学习范式
	- 自监督学习
	- 迁移学习（特征迁移、微调、领域自适应）
	- 元学习（Few-shot learning、MAML）
	- 在线学习与批量学习

## 模型评估与选择
- 偏差-方差权衡
- 超参数调优（网格搜索、随机搜索、贝叶斯优化）
- 学习曲线与验证曲线

### 风险函数

**核心定义**，在机器学习和统计学习的理论中，通常指 **期望风险**​ 或 **期望损失**。
它的定义是：**模型在整个数据分布（包括所有已见和未见的数据）上的平均损失**。

简单来说，它衡量的是**模型在“未来”或“真实世界”中表现好坏的期望值**，是我们最终追求的、最理想的优化目标。

---
 为什么需要风险函数？—— 从“经验”到“期望”的升华

要理解风险函数，必须和**损失函数**、**经验风险**放在一起看。这三者构成了一个完整的认知链条。

**1. 损失函数**
- **是什么**：衡量**单个样本**上，模型预测值与其实值之间的差异。比如，对一个样本预测房价错了10万元，损失可能就是10万的平方。
- **作用**：是衡量“错误”的尺子。
- **公式表示**：`L(y, f(x))`，其中 `y`是真实值，`f(x)`是模型预测值。
**2. 经验风险 （经验误差）**
- **是什么**：模型在**训练数据集**上的平均损失。也就是把你所有的训练样本的损失加起来，然后求个平均。
- **作用**：这是我们**在实际训练中能直接计算和优化的目标**。因为训练集是我们唯一拥有的数据。
- **公式表示**：`(1/N) * Σ L(y_i, f(x_i))`， 其中N是训练样本数。
**3. 风险函数**
- **是什么**：模型在**真实数据联合分布**​ `P(X, Y)`上的平均损失的期望值。它考虑的不是有限的训练集，而是理论上所有可能出现的（包括未来会遇到的）数据。
- **作用**：这是我们**真正关心的、但永远无法直接计算的终极目标**。它代表了模型的**泛化能力**。
- **公式表示**：`R(f) = E[L(y, f(x))] = ∫ L(y, f(x)) dP(x, y)`

### 损失函数

损失函数是以网络权重w和偏置b为变量的函数。

训练的整体思路：通过调整⽹络的权重参数，将输出值与⽬标值的差距尽可能缩⼩。
但实际训练的做法是通过找到损失函数的最⼩值，来找到其对应的权重参数，因此这个过程也叫反向传播。

**学习率**：决定每次参数更新的步⻓（学习率属于超参数，权重是普通参数，这⾥有⼀个参数与超参数的概念）

#### 均方误差MSE

$$
L(y, \hat{y}) = \frac{1}{N}\sum(y- \hat{y})^2 \\

\hat{y} = f(Wx+b)
$$
#### 交叉熵损失函数 Cross-Entropy Loss

交叉熵损失函数（Cross-Entropy Loss）是机器学习和深度学习中常用于分类任务（尤其是多分类）的一种损失函数。它的核心思想来源于信息论中的交叉熵，用于衡量模型预测的概率分布与真实标签（通常为 one-hot 编码）之间的差异。

公式
1. 二分类
$$
L(y,\hat{y})=−[ylog(\hat{y})+(1−y)log(1−\hat{y}​)]
$$
2. 多分类
假设有 CC 个类别。真实标签用 one-hot 向量 $y=[y_1​,y_2​,...,y_C​]$ 表示（其中只有一个 $y_i​=1$，其余为 0），模型输出的预测概率分布为 $\hat{y}​=[\hat{y}_1​,\hat{y}_2​,...,\hat{y}_C​]$（通常通过 softmax 激活函数得到，满足 $\sum\hat{y}_i = 1, \hat{y}_i \gt 0$）。

则交叉熵损失为：
$$L(y,\hat{y})=−\sum_{c=1}^{M}y_clog(\hat{y}_c​)$$
由于 yy 是 one-hot 向量，实际上只有真实类别的那一项非零，因此可简化为：
$$
L=−log(\hat{y}_k​)
$$
其中k是真实类别的索引
3. 批量样本的平均损失
$$
L_{total} = -\frac{1}{N}\sum_{n=1}^{N}y_{n,i}log(\hat{y}_{n,i})
$$
**参数含义：**
- y：**真实标签**。在分类中通常是 One-hot 编码（例如：如果是该类则为 1，否则为 0）。
- y^​：**预测概率**。模型通过 Softmax 等激活函数输出的预测值（取值在 0 到 1 之间）。

softmax

$$z=[z1​,z2​,…,zK​]$$
$$
q_i = \frac{e^{z_i}}{\sum_{j}e^{z_j}}
$$



### 欠拟合与过拟合


### 正则化

### 交叉验证
（K折、留一法）

## 模型求解算法

### 梯度下降法

### 牛顿法

## 模型评价指标

#### 回归模型指标

#### 分类模型性能指标
准确率**Accuracy**
精确率**Precision**
召回率 **Recall**
F1Score
ROC/AUC

|        | 真实癌症  | 真实未患癌 |
| ------ | ----- | ----- |
| 预测为患者  | TP=90 | FP=20 |
| 预测为未患癌 | FN=10 | TN=80 |


# 模型与算法
### 经典模型
- 线性模型
- 决策树与集成方法（Bagging、Random Forest、Boosting、XGBoost、LightGBM）
- 支持向量机（SVM）
- K近邻（KNN）
- 贝叶斯方法

### 神经网络与深度学习
#### 感知机与多层感知机（MLP）
#### 卷积神经网络（CNN）

![](https://i-blog.csdnimg.cn/direct/362764ce41484bfdb767be34c8dfd69e.gif)
#### 循环神经网络（RNN、LSTM、GRU）

RNN
- 自编码器（Auto-encoder）
- 生成对抗网络（GAN）
#### Transformer 与注意力机制
[attention is all you need](https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)


概念和结构
ANN

神经元

### 激活函数

sigmoid:  $f(x)=\frac{1}{1+e^{-x}}$

tanh函数:   $f(x)=\frac{1-e^{-2x}}{1+e^{-2x}}$

relu
$$
Relu = max(0,x)
$$

**Leaky ReLU**   
$$
f(x) =
\begin{cases} 
x,  & \mbox{if }x\mbox{ ≥ 0 } \\
\alpha x, & \mbox{if }x\mbox{ < 0}
\end{cases}
$$

softmax



梯度计算


